{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nA pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \\nThe system is controlled by applying a force of +1 or -1 to the cart. \\nThe pendulum starts upright, and the goal is to prevent it from falling over. \\nA reward of +1 is provided for every timestep that the pole remains upright.\\nThe episode ends when the pole is more than 15 degrees from vertical, or the \\ncart moves more than 2.4 units from the center.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "''' \n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \n",
    "The system is controlled by applying a force of +1 or -1 to the cart. \n",
    "The pendulum starts upright, and the goal is to prevent it from falling over. \n",
    "A reward of +1 is provided for every timestep that the pole remains upright.\n",
    "The episode ends when the pole is more than 15 degrees from vertical, or the \n",
    "cart moves more than 2.4 units from the center.\n",
    "'''\n",
    "\n",
    "# env.reset()    #returns an initial observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03046934  0.044385   -0.0095971   0.01338361]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "observation = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "args = dotdict({\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64, #256,\n",
    "    'pareto': 5000, # a factor to multiply action loss by to get optimal loss (5000 ish seems to work well)\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "    'goal_steps': 201, #200 is the limit for cart-pole\n",
    "    'score_requirement': 65,\n",
    "    'initial_games': 30000,\n",
    "    'policyUpdates': 2,    #10\n",
    "    'policyEpisodes': 250, #250\n",
    "})\n",
    "print(args.pareto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller (coach) Class: PI and Episode Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller():\n",
    "    \n",
    "    def __init__(self, nnet = None):\n",
    "        self.nnet = nnet   # the nnet \"is part of\" the controller -> composition (or aggregation?.. implemented by pointer/reference in c++)\n",
    "        #self.mcts = MCTS()\n",
    "        \n",
    "    def policyIteration(self):\n",
    "    \n",
    "        scores = np.array([])\n",
    "\n",
    "        #self.nnet = Net() # don't actually need to initiate the \"prev_nnet\", since it is defined when we create a controller object\n",
    "        init_examples, curr_mean, curr_median = initialExamples()  # Don't need to pass a model\n",
    "        a_loss, v_loss, batch_acc = self.nnet.train_model(examples = init_examples)\n",
    "\n",
    "        for i in range(args.policyUpdates):\n",
    "\n",
    "            # ----- GENERATE A BATCH OF EPISODES BASED ON THE PREVIOUS NET----------\n",
    "            exampleBatch = []\n",
    "            for e in range(args.policyEpisodes):\n",
    "                example = self.executeEpisode()\n",
    "                scores = np.append(scores, example[0, 5])\n",
    "\n",
    "                if len(exampleBatch) == 0:\n",
    "                    exampleBatch = example\n",
    "                else:\n",
    "                    exampleBatch = np.vstack(   (exampleBatch, example)   )\n",
    "\n",
    "\n",
    "            # -------- CREATE CHALLENGER POLICY BASED ON EXAMPLES GENERATED BY PREVIOUS POLICY -------------------\n",
    "            new_nnet = Net() # create a new net to train\n",
    "            a_loss, v_loss, batch_acc = new_nnet.train_model(examples = exampleBatch)\n",
    "\n",
    "\n",
    "            # -------- PRINT STATS ON NEW POLICY -------------\n",
    "            new_mean, new_median = np.mean(scores), np.median(scores)\n",
    "            print('Average accepted score: ', new_mean)\n",
    "            print('Median score for accepted scores: ', new_median)\n",
    "            print(Counter(scores))\n",
    "            print(\"Current Policy: \", curr_mean, curr_median)\n",
    "\n",
    "            # ---------- COMPARE AND UPDATE POLICIES --------------\n",
    "            if new_mean >= curr_mean and new_median >= curr_median:\n",
    "                self.nnet = new_nnet\n",
    "                curr_mean, curr_median = new_mean, new_median\n",
    "                print(\"Policy Updated!\")\n",
    "                print(\"New Policy: \", curr_mean, curr_median)\n",
    "\n",
    "        return self.nnet\n",
    "    \n",
    "    def executeEpisode(self):\n",
    "        ''' Generate and example episode of [4 x observation(t), action(t), E[return(t)]]. \n",
    "            All values are in a (n x 6) numpy array where n is the number of steps for the \n",
    "            episode to finish or the limit of 200 steps'''\n",
    "        score = 0\n",
    "        example = np.zeros((args.goal_steps, 6) )\n",
    "        prev_observation = env.reset() # list of 4 elements\n",
    "\n",
    "        # --------- ITERATE UP TO 500 STEPS PER EPISODE -------------\n",
    "        for t in range(args.goal_steps):\n",
    "\n",
    "            # --------- GENERATE ACTION ------------\n",
    "            # We can generate random actions or actions from the previous policy (i.e. prev nnet)\n",
    "            if self.nnet == None or t == 0:\n",
    "                action = env.action_space.sample()   # choose random action (0-left or 1-right)\n",
    "            else:\n",
    "                x = torch.tensor(   prev_observation,   dtype = torch.float    )\n",
    "                action_prob, e_score = self.nnet.forward(x)\n",
    "                action = np.argmax(   action_prob.detach().numpy()   )                \n",
    "\n",
    "            observation, reward, done, info = env.step(action)\n",
    "\n",
    "            # --------- STORE STATE-ACTION PAIR + SCORE ------------\n",
    "            example[t, 0:4] = prev_observation[0:4]\n",
    "            example[t, 4:6] = [action, score]\n",
    "\n",
    "            prev_observation = np.array(observation)\n",
    "            score += reward    # +1 for every frame we haven't fallen\n",
    "\n",
    "            if done: \n",
    "                break\n",
    "\n",
    "        example[:, 5] = score - example[:, 5]    # Convert scores to E[return] \n",
    "        return example[0:int(score), :] # we only want to return the parts with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialExamples():\n",
    "        allExamples = []\n",
    "        accepted_scores = np.array([])    # just the scores that met our threshold\n",
    "        init_controller = Controller()\n",
    "        init_controller.nnet = None                 # so that executeEpisode doesn't try anything weird\n",
    "\n",
    "        # --------------- ITERATE THROUGH 10000 EPISODE ------------------\n",
    "        for _ in range(args.initial_games):\n",
    "\n",
    "            exampleGame = init_controller.executeEpisode()\n",
    "\n",
    "            # --------- SAVE EXAMPLE (EPISODE) IF (SCORE > THRESHOLD) ----------\n",
    "            # Note, it does not save the score! Therefore all episodes with score > threshold\n",
    "            # are treated equally (not the best way of doing this!)\n",
    "            if exampleGame[0, 5] >= args.score_requirement:\n",
    "\n",
    "                accepted_scores = np.append(accepted_scores, exampleGame[0, 5])\n",
    "\n",
    "                if len(allExamples) == 0:\n",
    "                    allExamples = exampleGame\n",
    "                else:\n",
    "                    allExamples = np.vstack(   (allExamples, exampleGame)   )\n",
    "\n",
    "\n",
    "        # -------- PRINT STATS ------------\n",
    "        avg_mean, avg_median = np.mean(accepted_scores), np.median(accepted_scores)\n",
    "        print('Average accepted score: ', avg_mean)\n",
    "        print('Median score for accepted scores: ', avg_median)\n",
    "        print(Counter(accepted_scores))\n",
    "        print(len(accepted_scores))\n",
    "\n",
    "        return allExamples, avg_mean, avg_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Policy (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(4, 128)\n",
    "        self.l2 = nn.Linear(128, 256)\n",
    "        self.l3 = nn.Linear(256, 128)\n",
    "        self.l4 = nn.Linear(128, 32)\n",
    "        \n",
    "        self.dp = nn.Dropout(p = args.dropout)  # Suragnair used 0.3\n",
    "        self.a1 = nn.Linear(32, 2)    # want an action vector output: [log(prob right), log(prob left)]\n",
    "        self.v1 = nn.Linear(32, 32)\n",
    "        self.v2 = nn.Linear(32, 1)    # Output the expected return\n",
    "\n",
    "    def forward(self, obs):\n",
    "        #in_size = x.size(0)\n",
    "        x = F.relu(self.dp(self.l1(obs)))\n",
    "        x = F.relu(self.dp(self.l2(x)))\n",
    "        x = F.relu(self.dp(self.l3(x)))\n",
    "        x = F.relu(self.dp(self.l4(x)))\n",
    "        \n",
    "        #x = x.view(in_size, -1)  # flatten the tensor\n",
    "        a = self.a1(self.dp(x))\n",
    "        action_probs = F.log_softmax(a, dim = -1)    # choose the dimension such that we get something like \n",
    "                                                     # [exp(-0.6723) +  exp(-0.7144)] = 1 for the output\n",
    "        v = self.v2(self.dp(self.v1(x)))  # get a linear value for the expected return\n",
    "        return action_probs, v                      \n",
    "    \n",
    "    \n",
    "    def train_model(self, examples):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        action_loss, value_loss, accuracy = [], [], []\n",
    "\n",
    "        # ------------- CONVERT TO CORRECT DATA TYPE ----------------\n",
    "        gpu = torch.device(\"cpu\")\n",
    "        states = torch.tensor(  examples[:, 0:4] ,  dtype = torch.float)       #reshapes into a (23002, 4) array\n",
    "        target_actions = torch.tensor(  examples[:, 4], dtype = torch.long)    #reshapes into a (23002, 2) array \n",
    "        target_returns = torch.tensor(  examples[:, 5],  dtype = torch.float) \n",
    "        \n",
    "\n",
    "        #if args.cuda:  #if we're using the GPU:\n",
    "        #    states, target_actions, target_returns = states.contiguous().cuda(), target_actions.contiguous().cuda(), target_returns.contiguous().cuda()\n",
    "        #states, target_pis, target_vs = Variable(states), Variable(target_actions), Variable(target_returns)\n",
    "        # We should permute data before batching really. (X is a torch Variable)\n",
    "        #permutation = torch.randperm(X.size()[0])\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print('EPOCH ::: ' + str(epoch+1))\n",
    "            self.train()     # set module in training mode\n",
    "            batch_idx = 0\n",
    "            \n",
    "            for index in range(0, len(target_returns) - args.batch_size, args.batch_size):        \n",
    "\n",
    "                # -------- GET BATCHES -----------\n",
    "                #indices = permutation[i:i+batch_size]\n",
    "                batch_idx = int(index / args.batch_size) + 1 #add one so stats print properly\n",
    "                batch_states = states[index : index+args.batch_size] # torch.Size([64, 4])\n",
    "                batch_actions = target_actions[index : index+args.batch_size] # torch.Size([64])\n",
    "                batch_returns = target_returns[index: index+args.batch_size] # torch.Size([64])\n",
    "\n",
    "                # -------------------- FEED FORWARD ---------------------- \n",
    "                pred_actions, pred_return = self.forward(batch_states) # torch.Size([64, 2]) and torch.Size([64, 1])\n",
    "                batch_NumWrong = torch.abs(torch.argmax(pred_actions, dim = 1) - batch_actions).sum()\n",
    "            \n",
    "                a_loss = F.nll_loss(pred_actions, batch_actions, reduction = 'elementwise_mean')*args.pareto #standard is \"elementwise_mean\"\n",
    "                \n",
    "                #print(pred_actions.detach(), batch_actions.detach(), a_loss.detach())\n",
    "                \n",
    "                # Suragnair uses tanh for state_values, but their values are E[win] = [-1, 1] where -1 = loss\n",
    "                # Here we are using the length of time that we have been \"up\"\n",
    "                #v_loss = F.binary_cross_entropy(torch.sigmoid(pred_return[:, 0]), torch.sigmoid(batch_returns))\n",
    "                v_loss = F.mse_loss(pred_return[:, 0], batch_returns, reduction = 'elementwise_mean')\n",
    "\n",
    "                action_loss.append(a_loss);    value_loss.append(v_loss)\n",
    "                tot_loss = a_loss + v_loss\n",
    "\n",
    "                # ----------- COMPUTE GRADS AND BACKPROP ----------------\n",
    "                optimizer.zero_grad()\n",
    "                tot_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --------- PRINT STATS --------------\n",
    "                # Get array of predicted actions and compare with target actions to compute accuracy\n",
    "                \n",
    "                accuracy.append(  1 - (batch_NumWrong.detach().numpy()) / args.batch_size    ) #counts the different ones\n",
    "                if batch_idx % 8 == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tA-Loss: {:.4f}, V-Loss: {:.4f}\\tAccuracy: {:.5f}'.format(\n",
    "                            epoch+1, \n",
    "                            batch_idx * args.batch_size, \n",
    "                            states.size()[0],\n",
    "                            100 * batch_idx * args.batch_size / states.size()[0], \n",
    "                            a_loss,\n",
    "                            v_loss,\n",
    "                            accuracy[batch_idx - 1])\n",
    "\n",
    "                     )\n",
    "\n",
    "        return action_loss, value_loss, accuracy # removed self?\n",
    "    \n",
    "    def test(self, render = False):\n",
    "        self.eval()\n",
    "        scores, expected_scores, choices = [], np.zeros(args.goal_steps), []\n",
    "\n",
    "        # ------- PLAY SOME TEST GAMES ----------\n",
    "        for each_game in range(10):\n",
    "            env.reset()\n",
    "            score, E_score = 0, []\n",
    "            game_memory, prev_obs = [], []\n",
    "\n",
    "            for _ in range(args.goal_steps):    # play up to (200) frames\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                # ----- GENERATE AN ACTION -------\n",
    "                if len(prev_obs)==0:    # start by taking a random action\n",
    "                    action = env.action_space.sample()   \n",
    "\n",
    "                else:                   # After that take the best predicted action by the neural net\n",
    "                    x = torch.tensor(   prev_obs,   dtype = torch.float    )\n",
    "                    action_prob, e_score = self.forward(x)\n",
    "                    action = np.argmax(   action_prob.detach().numpy()   )\n",
    "                    E_score.append(   e_score.detach().numpy()   )  # see how the game updates it expected score as we move through\n",
    "\n",
    "                new_observation, reward, done, info = env.step(action)\n",
    "                prev_obs = new_observation\n",
    "\n",
    "                # ----- RECORD RESULTS -------\n",
    "                choices.append(action)   # just so we can work out the ratio of what we're predicting\n",
    "\n",
    "                game_memory.append([new_observation, action])\n",
    "                score += reward\n",
    "                if done: break\n",
    "\n",
    "            scores.append(score)    # Record the score of each game\n",
    "            padding = np.zeros(int(args.goal_steps - score + 1), dtype = int)\n",
    "            E_score = np.append([np.array(E_score)], [padding])\n",
    "            expected_scores = np.vstack((expected_scores, E_score))\n",
    "\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('choice 1 (right): {:.4f}  choice 0 (left): {:.4f}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "        print(Counter(scores))\n",
    "\n",
    "        x = np.linspace(1, len(expected_scores[0]), num = len(expected_scores[0]))\n",
    "        plt.plot(x, expected_scores[1])\n",
    "        plt.plot(x, expected_scores[3])\n",
    "        plt.xlabel(\"Steps taken\"); plt.ylabel(\"Expected Return (steps until failure)\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score:  76.49828178694158\n",
      "Median score for accepted scores:  73.0\n",
      "Counter({68.0: 23, 67.0: 22, 70.0: 21, 65.0: 20, 66.0: 19, 69.0: 15, 74.0: 14, 72.0: 13, 71.0: 12, 79.0: 11, 75.0: 10, 77.0: 10, 73.0: 10, 78.0: 9, 84.0: 8, 83.0: 8, 76.0: 6, 87.0: 5, 88.0: 5, 80.0: 4, 82.0: 4, 81.0: 4, 94.0: 4, 99.0: 3, 108.0: 3, 85.0: 3, 90.0: 3, 118.0: 2, 111.0: 2, 95.0: 2, 89.0: 2, 101.0: 2, 97.0: 2, 123.0: 1, 133.0: 1, 114.0: 1, 134.0: 1, 120.0: 1, 105.0: 1, 86.0: 1, 112.0: 1, 103.0: 1, 106.0: 1})\n",
      "291\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/22261 (2%)]\tA-Loss: 3456.4399, V-Loss: 1872.7842\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1024/22261 (5%)]\tA-Loss: 3399.6904, V-Loss: 1550.3081\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [1536/22261 (7%)]\tA-Loss: 3424.6160, V-Loss: 1394.8491\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [2048/22261 (9%)]\tA-Loss: 3457.3809, V-Loss: 1453.9479\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [2560/22261 (11%)]\tA-Loss: 3406.3467, V-Loss: 4103.3477\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [3072/22261 (14%)]\tA-Loss: 3426.7051, V-Loss: 1877.7870\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [3584/22261 (16%)]\tA-Loss: 3306.7393, V-Loss: 1876.9183\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [4096/22261 (18%)]\tA-Loss: 3392.9333, V-Loss: 5803.2632\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [4608/22261 (21%)]\tA-Loss: 3372.4502, V-Loss: 2383.7480\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [5120/22261 (23%)]\tA-Loss: 3353.3535, V-Loss: 1368.9178\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [5632/22261 (25%)]\tA-Loss: 3327.2380, V-Loss: 1870.6277\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [6144/22261 (28%)]\tA-Loss: 3454.2710, V-Loss: 2898.0884\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [6656/22261 (30%)]\tA-Loss: 3404.1953, V-Loss: 1852.6177\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [7168/22261 (32%)]\tA-Loss: 3326.3325, V-Loss: 1894.3170\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [7680/22261 (34%)]\tA-Loss: 3455.2969, V-Loss: 2011.6781\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [8192/22261 (37%)]\tA-Loss: 3418.0366, V-Loss: 1261.8661\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [8704/22261 (39%)]\tA-Loss: 3556.4861, V-Loss: 1039.8732\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [9216/22261 (41%)]\tA-Loss: 3224.0742, V-Loss: 906.9854\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [9728/22261 (44%)]\tA-Loss: 3360.4224, V-Loss: 663.9470\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [10240/22261 (46%)]\tA-Loss: 3505.3884, V-Loss: 557.3314\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [10752/22261 (48%)]\tA-Loss: 3857.0632, V-Loss: 404.8386\tAccuracy: 0.42188\n",
      "Train Epoch: 1 [11264/22261 (51%)]\tA-Loss: 3523.6650, V-Loss: 448.4507\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [11776/22261 (53%)]\tA-Loss: 3294.5017, V-Loss: 511.4832\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [12288/22261 (55%)]\tA-Loss: 3276.4983, V-Loss: 3114.2996\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [12800/22261 (57%)]\tA-Loss: 3498.2634, V-Loss: 529.0706\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [13312/22261 (60%)]\tA-Loss: 3387.7615, V-Loss: 863.3287\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [13824/22261 (62%)]\tA-Loss: 3362.6738, V-Loss: 1810.2247\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [14336/22261 (64%)]\tA-Loss: 3496.7944, V-Loss: 715.5203\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [14848/22261 (67%)]\tA-Loss: 3536.2754, V-Loss: 1444.6897\tAccuracy: 0.43750\n",
      "Train Epoch: 1 [15360/22261 (69%)]\tA-Loss: 3366.6038, V-Loss: 400.3659\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [15872/22261 (71%)]\tA-Loss: 3281.7534, V-Loss: 340.4542\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [16384/22261 (74%)]\tA-Loss: 3259.8516, V-Loss: 609.4364\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [16896/22261 (76%)]\tA-Loss: 3409.3438, V-Loss: 410.4766\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [17408/22261 (78%)]\tA-Loss: 3287.1633, V-Loss: 491.4555\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [17920/22261 (80%)]\tA-Loss: 3401.8279, V-Loss: 456.5238\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [18432/22261 (83%)]\tA-Loss: 3431.1846, V-Loss: 1093.7672\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [18944/22261 (85%)]\tA-Loss: 3449.5168, V-Loss: 547.6321\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [19456/22261 (87%)]\tA-Loss: 3515.3582, V-Loss: 360.1863\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [19968/22261 (90%)]\tA-Loss: 3373.6445, V-Loss: 938.1713\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [20480/22261 (92%)]\tA-Loss: 3332.3386, V-Loss: 279.0552\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [20992/22261 (94%)]\tA-Loss: 3257.9192, V-Loss: 547.1323\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [21504/22261 (97%)]\tA-Loss: 3426.0220, V-Loss: 303.6310\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [22016/22261 (99%)]\tA-Loss: 3471.4729, V-Loss: 496.4040\tAccuracy: 0.54688\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/44129 (1%)]\tA-Loss: 3475.9504, V-Loss: 12749.8564\tAccuracy: 0.40625\n",
      "Train Epoch: 1 [1024/44129 (2%)]\tA-Loss: 3442.0120, V-Loss: 19207.0078\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [1536/44129 (3%)]\tA-Loss: 3366.7576, V-Loss: 22927.8574\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [2048/44129 (5%)]\tA-Loss: 3311.5500, V-Loss: 6205.5356\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [2560/44129 (6%)]\tA-Loss: 3263.2483, V-Loss: 15007.9160\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [3072/44129 (7%)]\tA-Loss: 3182.0232, V-Loss: 8611.9854\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [3584/44129 (8%)]\tA-Loss: 3588.1389, V-Loss: 11091.6816\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [4096/44129 (9%)]\tA-Loss: 2939.2288, V-Loss: 3373.7036\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [4608/44129 (10%)]\tA-Loss: 2624.3972, V-Loss: 9069.0000\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [5120/44129 (12%)]\tA-Loss: 2633.6604, V-Loss: 16102.4609\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [5632/44129 (13%)]\tA-Loss: 2892.3357, V-Loss: 6849.2500\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [6144/44129 (14%)]\tA-Loss: 3323.6604, V-Loss: 1206.9615\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [6656/44129 (15%)]\tA-Loss: 2979.5178, V-Loss: 3536.6575\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [7168/44129 (16%)]\tA-Loss: 3453.8149, V-Loss: 2374.9290\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [7680/44129 (17%)]\tA-Loss: 3414.0430, V-Loss: 1878.7306\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [8192/44129 (19%)]\tA-Loss: 3444.4233, V-Loss: 1062.4602\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [8704/44129 (20%)]\tA-Loss: 4184.9668, V-Loss: 533.2037\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [9216/44129 (21%)]\tA-Loss: 4034.3999, V-Loss: 907.9642\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [9728/44129 (22%)]\tA-Loss: 2721.8342, V-Loss: 488.8838\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [10240/44129 (23%)]\tA-Loss: 3718.2136, V-Loss: 7746.1230\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [10752/44129 (24%)]\tA-Loss: 3876.8062, V-Loss: 1606.3824\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [11264/44129 (26%)]\tA-Loss: 3039.1021, V-Loss: 3574.0244\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [11776/44129 (27%)]\tA-Loss: 3554.3606, V-Loss: 655.9522\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [12288/44129 (28%)]\tA-Loss: 3036.7686, V-Loss: 637.3228\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [12800/44129 (29%)]\tA-Loss: 3248.4548, V-Loss: 4872.8701\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [13312/44129 (30%)]\tA-Loss: 3152.9697, V-Loss: 258.1250\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [13824/44129 (31%)]\tA-Loss: 2869.3811, V-Loss: 1358.3649\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [14336/44129 (32%)]\tA-Loss: 2976.2524, V-Loss: 1105.4357\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [14848/44129 (34%)]\tA-Loss: 3547.8220, V-Loss: 1396.2478\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [15360/44129 (35%)]\tA-Loss: 2556.9136, V-Loss: 851.1210\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [15872/44129 (36%)]\tA-Loss: 2857.5649, V-Loss: 1054.7241\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [16384/44129 (37%)]\tA-Loss: 3105.7710, V-Loss: 2185.4675\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [16896/44129 (38%)]\tA-Loss: 2785.3875, V-Loss: 660.9539\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [17408/44129 (39%)]\tA-Loss: 2733.8523, V-Loss: 1662.5831\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [17920/44129 (41%)]\tA-Loss: 2910.2048, V-Loss: 1337.7441\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [18432/44129 (42%)]\tA-Loss: 3086.9031, V-Loss: 3922.4727\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [18944/44129 (43%)]\tA-Loss: 3128.0400, V-Loss: 2439.3689\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [19456/44129 (44%)]\tA-Loss: 2513.1345, V-Loss: 789.0969\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [19968/44129 (45%)]\tA-Loss: 3034.0757, V-Loss: 761.6545\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [20480/44129 (46%)]\tA-Loss: 3265.7200, V-Loss: 877.5878\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [20992/44129 (48%)]\tA-Loss: 2831.1277, V-Loss: 2855.9666\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [21504/44129 (49%)]\tA-Loss: 3251.7573, V-Loss: 585.2262\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [22016/44129 (50%)]\tA-Loss: 3002.9143, V-Loss: 1510.0127\tAccuracy: 0.67188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [22528/44129 (51%)]\tA-Loss: 3008.0459, V-Loss: 1716.7920\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [23040/44129 (52%)]\tA-Loss: 2791.9858, V-Loss: 9434.0859\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [23552/44129 (53%)]\tA-Loss: 2830.2141, V-Loss: 370.9794\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [24064/44129 (55%)]\tA-Loss: 2822.2725, V-Loss: 631.4641\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [24576/44129 (56%)]\tA-Loss: 2986.6172, V-Loss: 1036.5375\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [25088/44129 (57%)]\tA-Loss: 2975.5701, V-Loss: 4536.8418\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [25600/44129 (58%)]\tA-Loss: 2922.4204, V-Loss: 2274.8586\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [26112/44129 (59%)]\tA-Loss: 3016.7461, V-Loss: 580.8220\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [26624/44129 (60%)]\tA-Loss: 2979.7605, V-Loss: 430.3616\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [27136/44129 (61%)]\tA-Loss: 2842.3977, V-Loss: 1216.5588\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [27648/44129 (63%)]\tA-Loss: 2663.4697, V-Loss: 1085.8735\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [28160/44129 (64%)]\tA-Loss: 3499.3845, V-Loss: 977.2452\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [28672/44129 (65%)]\tA-Loss: 2881.8765, V-Loss: 621.5840\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [29184/44129 (66%)]\tA-Loss: 2601.3796, V-Loss: 2691.0425\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [29696/44129 (67%)]\tA-Loss: 2844.5974, V-Loss: 1620.1067\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [30208/44129 (68%)]\tA-Loss: 2655.0229, V-Loss: 2062.3044\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [30720/44129 (70%)]\tA-Loss: 2914.2136, V-Loss: 606.3639\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [31232/44129 (71%)]\tA-Loss: 2992.2588, V-Loss: 2106.9873\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [31744/44129 (72%)]\tA-Loss: 2612.3694, V-Loss: 1257.5839\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [32256/44129 (73%)]\tA-Loss: 2655.5144, V-Loss: 3635.5847\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [32768/44129 (74%)]\tA-Loss: 3069.0649, V-Loss: 2931.5073\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [33280/44129 (75%)]\tA-Loss: 3224.0115, V-Loss: 1556.2181\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [33792/44129 (77%)]\tA-Loss: 3089.5601, V-Loss: 5583.6055\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [34304/44129 (78%)]\tA-Loss: 2698.4360, V-Loss: 3651.0786\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [34816/44129 (79%)]\tA-Loss: 2538.1392, V-Loss: 3040.7100\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [35328/44129 (80%)]\tA-Loss: 2582.5981, V-Loss: 1175.1246\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [35840/44129 (81%)]\tA-Loss: 2867.3306, V-Loss: 1074.0015\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [36352/44129 (82%)]\tA-Loss: 2704.0986, V-Loss: 2199.7798\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [36864/44129 (84%)]\tA-Loss: 2935.7014, V-Loss: 325.3859\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [37376/44129 (85%)]\tA-Loss: 2975.6213, V-Loss: 3411.2988\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [37888/44129 (86%)]\tA-Loss: 3043.3950, V-Loss: 585.0040\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [38400/44129 (87%)]\tA-Loss: 3053.7600, V-Loss: 246.8342\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [38912/44129 (88%)]\tA-Loss: 2647.9270, V-Loss: 601.2111\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [39424/44129 (89%)]\tA-Loss: 2652.6025, V-Loss: 2121.9385\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [39936/44129 (90%)]\tA-Loss: 2745.4495, V-Loss: 674.3656\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [40448/44129 (92%)]\tA-Loss: 2760.9744, V-Loss: 796.5927\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [40960/44129 (93%)]\tA-Loss: 2576.9082, V-Loss: 1235.9559\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [41472/44129 (94%)]\tA-Loss: 2546.6309, V-Loss: 2076.8691\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [41984/44129 (95%)]\tA-Loss: 3417.0435, V-Loss: 832.1055\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [42496/44129 (96%)]\tA-Loss: 3230.4624, V-Loss: 903.6412\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [43008/44129 (97%)]\tA-Loss: 2621.8472, V-Loss: 1875.9692\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [43520/44129 (99%)]\tA-Loss: 3071.6956, V-Loss: 1571.9344\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [44032/44129 (100%)]\tA-Loss: 2556.5659, V-Loss: 1397.1801\tAccuracy: 0.76562\n",
      "Average accepted score:  176.516\n",
      "Median score for accepted scores:  182.0\n",
      "Counter({200.0: 77, 167.0: 5, 163.0: 5, 156.0: 5, 180.0: 5, 155.0: 5, 184.0: 5, 149.0: 5, 169.0: 5, 191.0: 4, 151.0: 4, 182.0: 4, 144.0: 4, 197.0: 4, 161.0: 4, 194.0: 4, 195.0: 4, 166.0: 4, 147.0: 3, 179.0: 3, 145.0: 3, 173.0: 3, 187.0: 3, 138.0: 3, 193.0: 3, 185.0: 3, 139.0: 3, 146.0: 3, 190.0: 3, 189.0: 3, 171.0: 2, 160.0: 2, 199.0: 2, 168.0: 2, 154.0: 2, 176.0: 2, 150.0: 2, 186.0: 2, 188.0: 2, 192.0: 2, 172.0: 2, 129.0: 2, 165.0: 2, 159.0: 2, 142.0: 2, 177.0: 2, 174.0: 2, 131.0: 2, 158.0: 2, 175.0: 2, 127.0: 2, 140.0: 1, 198.0: 1, 125.0: 1, 114.0: 1, 196.0: 1, 153.0: 1, 143.0: 1, 183.0: 1, 152.0: 1, 120.0: 1, 141.0: 1, 178.0: 1, 164.0: 1, 162.0: 1, 110.0: 1, 181.0: 1, 136.0: 1, 122.0: 1, 133.0: 1})\n",
      "Current Policy:  76.49828178694158 73.0\n",
      "Policy Updated!\n",
      "New Policy:  176.516 182.0\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/45402 (1%)]\tA-Loss: 3489.7947, V-Loss: 12090.7793\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1024/45402 (2%)]\tA-Loss: 3420.3052, V-Loss: 16048.8584\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [1536/45402 (3%)]\tA-Loss: 3374.3977, V-Loss: 28065.2949\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [2048/45402 (5%)]\tA-Loss: 3360.3962, V-Loss: 1588.4371\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [2560/45402 (6%)]\tA-Loss: 3239.3982, V-Loss: 3051.4504\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [3072/45402 (7%)]\tA-Loss: 3050.1816, V-Loss: 9898.1123\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [3584/45402 (8%)]\tA-Loss: 3255.6738, V-Loss: 25849.7422\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [4096/45402 (9%)]\tA-Loss: 2765.7068, V-Loss: 3657.3987\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [4608/45402 (10%)]\tA-Loss: 2738.0037, V-Loss: 7761.5933\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [5120/45402 (11%)]\tA-Loss: 2397.9954, V-Loss: 4081.7646\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [5632/45402 (12%)]\tA-Loss: 2531.3086, V-Loss: 3091.0173\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [6144/45402 (14%)]\tA-Loss: 3029.1470, V-Loss: 18853.0039\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [6656/45402 (15%)]\tA-Loss: 2531.1484, V-Loss: 9172.9189\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [7168/45402 (16%)]\tA-Loss: 2963.7346, V-Loss: 1376.4102\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [7680/45402 (17%)]\tA-Loss: 3192.8896, V-Loss: 1794.1355\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [8192/45402 (18%)]\tA-Loss: 4397.6787, V-Loss: 10605.5332\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [8704/45402 (19%)]\tA-Loss: 2963.0945, V-Loss: 2669.5159\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [9216/45402 (20%)]\tA-Loss: 4244.3418, V-Loss: 10811.2686\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [9728/45402 (21%)]\tA-Loss: 2473.6619, V-Loss: 3121.1682\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [10240/45402 (23%)]\tA-Loss: 3785.3450, V-Loss: 2590.0625\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [10752/45402 (24%)]\tA-Loss: 3662.5735, V-Loss: 4239.0347\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [11264/45402 (25%)]\tA-Loss: 3538.4702, V-Loss: 8955.8203\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [11776/45402 (26%)]\tA-Loss: 2125.7163, V-Loss: 5427.5669\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [12288/45402 (27%)]\tA-Loss: 2489.6262, V-Loss: 3423.0339\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [12800/45402 (28%)]\tA-Loss: 2849.6057, V-Loss: 4977.3018\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [13312/45402 (29%)]\tA-Loss: 2111.9004, V-Loss: 1824.3883\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [13824/45402 (30%)]\tA-Loss: 2072.7036, V-Loss: 1214.1335\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [14336/45402 (32%)]\tA-Loss: 2313.5278, V-Loss: 1797.0060\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [14848/45402 (33%)]\tA-Loss: 2162.9788, V-Loss: 4364.5635\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [15360/45402 (34%)]\tA-Loss: 2880.9771, V-Loss: 6859.7476\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [15872/45402 (35%)]\tA-Loss: 1933.4691, V-Loss: 929.9642\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [16384/45402 (36%)]\tA-Loss: 2263.9380, V-Loss: 2252.9399\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [16896/45402 (37%)]\tA-Loss: 2332.4800, V-Loss: 4141.3066\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [17408/45402 (38%)]\tA-Loss: 2458.2048, V-Loss: 5353.2393\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [17920/45402 (39%)]\tA-Loss: 2390.2000, V-Loss: 3759.8198\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [18432/45402 (41%)]\tA-Loss: 2342.4333, V-Loss: 1433.2806\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [18944/45402 (42%)]\tA-Loss: 2469.9509, V-Loss: 1398.7013\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [19456/45402 (43%)]\tA-Loss: 2553.5071, V-Loss: 1232.2635\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [19968/45402 (44%)]\tA-Loss: 2464.1343, V-Loss: 4637.2876\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [20480/45402 (45%)]\tA-Loss: 2499.5728, V-Loss: 4316.4316\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [20992/45402 (46%)]\tA-Loss: 1903.1816, V-Loss: 1058.3489\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [21504/45402 (47%)]\tA-Loss: 1905.2704, V-Loss: 486.7645\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [22016/45402 (48%)]\tA-Loss: 2270.9634, V-Loss: 2705.8882\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [22528/45402 (50%)]\tA-Loss: 2264.8796, V-Loss: 652.9709\tAccuracy: 0.79688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23040/45402 (51%)]\tA-Loss: 1872.0797, V-Loss: 2008.3635\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [23552/45402 (52%)]\tA-Loss: 1900.9922, V-Loss: 5631.6025\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [24064/45402 (53%)]\tA-Loss: 2525.6069, V-Loss: 1683.0215\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [24576/45402 (54%)]\tA-Loss: 2157.8901, V-Loss: 291.1152\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [25088/45402 (55%)]\tA-Loss: 2236.9089, V-Loss: 960.1568\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [25600/45402 (56%)]\tA-Loss: 1562.1285, V-Loss: 627.5513\tAccuracy: 0.92188\n",
      "Train Epoch: 1 [26112/45402 (58%)]\tA-Loss: 2017.8164, V-Loss: 1331.2778\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [26624/45402 (59%)]\tA-Loss: 2437.9233, V-Loss: 6854.2227\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [27136/45402 (60%)]\tA-Loss: 2092.6104, V-Loss: 1465.6733\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [27648/45402 (61%)]\tA-Loss: 1949.6805, V-Loss: 3231.8621\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [28160/45402 (62%)]\tA-Loss: 2016.9735, V-Loss: 1855.7372\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [28672/45402 (63%)]\tA-Loss: 2401.4070, V-Loss: 1891.0411\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [29184/45402 (64%)]\tA-Loss: 1872.4591, V-Loss: 4538.5278\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [29696/45402 (65%)]\tA-Loss: 1730.3521, V-Loss: 1054.3903\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [30208/45402 (67%)]\tA-Loss: 1860.6055, V-Loss: 3735.7012\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [30720/45402 (68%)]\tA-Loss: 2233.5732, V-Loss: 2502.7249\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [31232/45402 (69%)]\tA-Loss: 2539.1296, V-Loss: 2384.7195\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [31744/45402 (70%)]\tA-Loss: 2190.6731, V-Loss: 3895.4788\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [32256/45402 (71%)]\tA-Loss: 1674.0234, V-Loss: 382.0258\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [32768/45402 (72%)]\tA-Loss: 2666.8733, V-Loss: 1028.3855\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [33280/45402 (73%)]\tA-Loss: 2741.0972, V-Loss: 1722.0596\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [33792/45402 (74%)]\tA-Loss: 2443.7168, V-Loss: 1683.7087\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [34304/45402 (76%)]\tA-Loss: 2212.0635, V-Loss: 1843.7793\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [34816/45402 (77%)]\tA-Loss: 2155.4285, V-Loss: 2109.6321\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [35328/45402 (78%)]\tA-Loss: 2265.7539, V-Loss: 4703.1445\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [35840/45402 (79%)]\tA-Loss: 2040.8967, V-Loss: 915.1202\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [36352/45402 (80%)]\tA-Loss: 1351.6539, V-Loss: 763.2676\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [36864/45402 (81%)]\tA-Loss: 2359.2095, V-Loss: 2200.1580\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [37376/45402 (82%)]\tA-Loss: 2595.0159, V-Loss: 597.1960\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [37888/45402 (83%)]\tA-Loss: 2086.9941, V-Loss: 2084.3806\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [38400/45402 (85%)]\tA-Loss: 2238.4817, V-Loss: 1101.9475\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [38912/45402 (86%)]\tA-Loss: 2304.6194, V-Loss: 966.8894\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [39424/45402 (87%)]\tA-Loss: 1967.4424, V-Loss: 2471.6677\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [39936/45402 (88%)]\tA-Loss: 2631.8206, V-Loss: 2214.8608\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [40448/45402 (89%)]\tA-Loss: 2447.4138, V-Loss: 365.8354\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [40960/45402 (90%)]\tA-Loss: 1791.3848, V-Loss: 755.3318\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [41472/45402 (91%)]\tA-Loss: 1742.4446, V-Loss: 991.3947\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [41984/45402 (92%)]\tA-Loss: 1979.8589, V-Loss: 1379.4095\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [42496/45402 (94%)]\tA-Loss: 1977.1725, V-Loss: 1642.4633\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [43008/45402 (95%)]\tA-Loss: 2216.2400, V-Loss: 425.4577\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [43520/45402 (96%)]\tA-Loss: 1606.5371, V-Loss: 663.8343\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [44032/45402 (97%)]\tA-Loss: 2438.0632, V-Loss: 844.2725\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [44544/45402 (98%)]\tA-Loss: 2003.1248, V-Loss: 1586.0740\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [45056/45402 (99%)]\tA-Loss: 2106.1824, V-Loss: 1336.3914\tAccuracy: 0.78125\n",
      "Average accepted score:  179.062\n",
      "Median score for accepted scores:  187.0\n",
      "Counter({200.0: 197, 167.0: 8, 163.0: 8, 155.0: 8, 151.0: 7, 182.0: 7, 180.0: 7, 144.0: 7, 185.0: 7, 149.0: 7, 169.0: 7, 194.0: 7, 189.0: 7, 147.0: 6, 171.0: 6, 156.0: 6, 184.0: 6, 150.0: 6, 190.0: 6, 195.0: 6, 177.0: 6, 166.0: 6, 179.0: 5, 173.0: 5, 160.0: 5, 153.0: 5, 138.0: 5, 161.0: 5, 191.0: 4, 145.0: 4, 187.0: 4, 197.0: 4, 186.0: 4, 188.0: 4, 192.0: 4, 172.0: 4, 146.0: 4, 165.0: 4, 142.0: 4, 164.0: 4, 162.0: 4, 158.0: 4, 175.0: 4, 133.0: 4, 199.0: 3, 168.0: 3, 154.0: 3, 193.0: 3, 176.0: 3, 139.0: 3, 152.0: 3, 174.0: 3, 178.0: 3, 136.0: 3, 127.0: 3, 157.0: 3, 170.0: 3, 148.0: 3, 140.0: 2, 125.0: 2, 143.0: 2, 129.0: 2, 183.0: 2, 159.0: 2, 131.0: 2, 181.0: 2, 198.0: 1, 114.0: 1, 196.0: 1, 120.0: 1, 141.0: 1, 110.0: 1, 122.0: 1, 134.0: 1, 137.0: 1, 135.0: 1})\n",
      "Current Policy:  176.516 182.0\n",
      "Policy Updated!\n",
      "New Policy:  179.062 187.0\n"
     ]
    }
   ],
   "source": [
    "test = Controller(Net())\n",
    "best_model = test.policyIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 163.6\n",
      "choice 1 (right): 0.5367  choice 0 (left): 0.4633\n",
      "Counter({159.0: 2, 200.0: 1, 136.0: 1, 156.0: 1, 180.0: 1, 189.0: 1, 166.0: 1, 127.0: 1, 164.0: 1})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.test(render = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suragnair's MCTS Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "\n",
    "    def __init__(self, nnet):\n",
    "        self.nnet = nnet    #fuction handle\n",
    "        self.c_puct = 0.1\n",
    "        self.Qsa = {}       # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores #times edge s,a was visited\n",
    "        self.Ns = {}        # stores #times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "    def search(self, s, reward, done):\n",
    "        # ---------------- TERMINAL STATE ---------------\n",
    "        if done == True:\n",
    "            return reward\n",
    "\n",
    "        # ------------- EXPLORING FROM A LEAF NODE ----------------------\n",
    "        #check if the state has a policy from it yet, if not then its a leaf\n",
    "        if s not in self.Ps:\n",
    "            self.Ps[s], v = self.nnet.predict(s)\n",
    "            \n",
    "            #check if the neural net has assigned a +ve prob to any policy\n",
    "             \n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s    # renormalize\n",
    "            else:\n",
    "                # if they were all zero then they are equally probable: (this shouldn't usually happen)\n",
    "                # NB! All valid moves may = 0 if NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                print(\"All valid moves were masked, do workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "        \n",
    "\n",
    "        # ------------- GET BEST ACTION -----------------------------\n",
    "        # search through the valid actions and update the UCB for all actions then update best acions\n",
    "        max_u, best_a = -float(\"inf\"), -1\n",
    "        for a in range(1):\n",
    "            if (s,a) in self.Qsa:\n",
    "                u = self.Qsa[(s,a)] + self.cpuct*self.Ps[s][a]*np.sqrt(self.Ns[s])/(1+self.Nsa[(s,a)])\n",
    "            else:\n",
    "                u = self.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s] + 1e-8)     # Q = 0 ?\n",
    "            \n",
    "            if u > max_u:\n",
    "                max_u = u\n",
    "                best_a = a\n",
    "        a = best_a\n",
    "\n",
    "        \n",
    "        # ----------- RECURSION TO NEXT STATE ------------------------\n",
    "        sp, reward, done, info = env.step(a)\n",
    "        v = self.search(sp, reward, done)\n",
    "        \n",
    "\n",
    "        # ------------ BACKUP Q-VALUES AND N_VISITED -----------------\n",
    "        # after we reach the terminal condition then the stack unwinds and we\n",
    "        # propagate up the tree backing up Q and N as we go\n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)]*self.Qsa[(s,a)] + v)/(self.Nsa[(s,a)]+1)\n",
    "            self.Nsa[(s,a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
