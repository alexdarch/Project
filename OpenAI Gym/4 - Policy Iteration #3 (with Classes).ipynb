{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nA pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \\nThe system is controlled by applying a force of +1 or -1 to the cart. \\nThe pendulum starts upright, and the goal is to prevent it from falling over. \\nA reward of +1 is provided for every timestep that the pole remains upright.\\nThe episode ends when the pole is more than 15 degrees from vertical, or the \\ncart moves more than 2.4 units from the center.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "''' \n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \n",
    "The system is controlled by applying a force of +1 or -1 to the cart. \n",
    "The pendulum starts upright, and the goal is to prevent it from falling over. \n",
    "A reward of +1 is provided for every timestep that the pole remains upright.\n",
    "The episode ends when the pole is more than 15 degrees from vertical, or the \n",
    "cart moves more than 2.4 units from the center.\n",
    "'''\n",
    "\n",
    "# env.reset()    #returns an initial observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03114862 -0.00305378  0.04323621 -0.01549823]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "observation = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "args = dotdict({\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64, #256,\n",
    "    'pareto': 5000, # a factor to multiply action loss by to get optimal loss (5000 ish seems to work well)\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "    'goal_steps': 201, #200 is the limit for cart-pole\n",
    "    'score_requirement': 65,\n",
    "    'initial_games': 30000,\n",
    "    'policyUpdates': 2,    #10\n",
    "    'policyEpisodes': 250, #250\n",
    "})\n",
    "print(args.pareto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller (coach) Class: PI and Episode Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller():\n",
    "    \n",
    "    def __init__(self, nnet = None):\n",
    "        self.nnet = nnet   # the nnet \"is part of\" the controller -> composition (or aggregation?.. implemented by pointer/reference in c++)\n",
    "        #self.mcts = MCTS()\n",
    "        \n",
    "    def policyIteration(self):\n",
    "    \n",
    "        scores = np.array([])\n",
    "\n",
    "        #self.nnet = Net() # don't actually need to initiate the \"prev_nnet\", since it is defined when we create a controller object\n",
    "        init_examples, curr_mean, curr_median = initialExamples()  # Don't need to pass a model\n",
    "        a_loss, v_loss, batch_acc = self.nnet.train_model(examples = init_examples)\n",
    "\n",
    "        for i in range(args.policyUpdates):\n",
    "\n",
    "            # ----- GENERATE A NEW BATCH OF EPISODES BASED ON THE CURRENT NET----------\n",
    "            exampleBatch = []\n",
    "            for e in range(args.policyEpisodes):\n",
    "                example = self.executeEpisode()\n",
    "                scores = np.append(scores, example[0, 5])\n",
    "\n",
    "                if len(exampleBatch) == 0:\n",
    "                    exampleBatch = example\n",
    "                else:\n",
    "                    exampleBatch = np.vstack(   (exampleBatch, example)   )\n",
    "\n",
    "\n",
    "            # -------- CREATE CHALLENGER POLICY BASED ON EXAMPLES GENERATED BY PREVIOUS POLICY -------------------\n",
    "            new_nnet = Net() # create a new net to train\n",
    "            a_loss, v_loss, batch_acc = new_nnet.train_model(examples = exampleBatch)\n",
    "\n",
    "\n",
    "            # -------- PRINT STATS ON NEW POLICY -------------\n",
    "            new_mean, new_median = np.mean(scores), np.median(scores)\n",
    "            print('Average accepted score: ', new_mean)\n",
    "            print('Median score for accepted scores: ', new_median)\n",
    "            print(Counter(scores))\n",
    "            print(\"Current Policy: \", curr_mean, curr_median)\n",
    "\n",
    "            # ---------- COMPARE AND UPDATE POLICIES --------------\n",
    "            if new_mean >= curr_mean and new_median >= curr_median:\n",
    "                self.nnet = new_nnet\n",
    "                curr_mean, curr_median = new_mean, new_median\n",
    "                print(\"Policy Updated!\")\n",
    "                print(\"New Policy: \", curr_mean, curr_median)\n",
    "\n",
    "        return self.nnet\n",
    "    \n",
    "    def executeEpisode(self):\n",
    "        ''' Generate and example episode of [4 x observation(t), action(t), E[return(t)]]. \n",
    "            All values are in a (n x 6) numpy array where n is the number of steps for the \n",
    "            episode to finish or the limit of 200 steps'''\n",
    "        score = 0\n",
    "        example = np.zeros((args.goal_steps, 6) )\n",
    "        prev_observation = env.reset() # list of 4 elements\n",
    "\n",
    "        # --------- ITERATE UP TO 500 STEPS PER EPISODE -------------\n",
    "        for t in range(args.goal_steps):\n",
    "\n",
    "            # --------- GENERATE ACTION ------------\n",
    "            # We can generate random actions or actions from the previous policy (i.e. prev nnet)\n",
    "            if self.nnet == None or t == 0:\n",
    "                action = env.action_space.sample()   # choose random action (0-left or 1-right)\n",
    "            else:\n",
    "                x = torch.tensor(   prev_observation,   dtype = torch.float    )\n",
    "                action_prob, e_score = self.nnet.forward(x)\n",
    "                action = np.argmax(   action_prob.detach().numpy()   )                \n",
    "\n",
    "            observation, reward, done, info = env.step(action)\n",
    "\n",
    "            # --------- STORE STATE-ACTION PAIR + SCORE ------------\n",
    "            example[t, 0:4] = prev_observation[0:4]\n",
    "            example[t, 4:6] = [action, score]\n",
    "\n",
    "            prev_observation = np.array(observation)\n",
    "            score += reward    # +1 for every frame we haven't fallen\n",
    "\n",
    "            if done: \n",
    "                break\n",
    "\n",
    "        example[:, 5] = score - example[:, 5]    # Convert scores to E[return] \n",
    "        return example[0:int(score), :] # we only want to return the parts with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialExamples():\n",
    "        allExamples = []\n",
    "        accepted_scores = np.array([])    # just the scores that met our threshold\n",
    "        init_controller = Controller()\n",
    "        init_controller.nnet = None                 # so that executeEpisode doesn't try anything weird\n",
    "\n",
    "        # --------------- ITERATE THROUGH 10000 EPISODE ------------------\n",
    "        for _ in range(args.initial_games):\n",
    "\n",
    "            exampleGame = init_controller.executeEpisode()\n",
    "\n",
    "            # --------- SAVE EXAMPLE (EPISODE) IF (SCORE > THRESHOLD) ----------\n",
    "            # Note, it does not save the score! Therefore all episodes with score > threshold\n",
    "            # are treated equally (not the best way of doing this!)\n",
    "            if exampleGame[0, 5] >= args.score_requirement:\n",
    "\n",
    "                accepted_scores = np.append(accepted_scores, exampleGame[0, 5])\n",
    "\n",
    "                if len(allExamples) == 0:\n",
    "                    allExamples = exampleGame\n",
    "                else:\n",
    "                    allExamples = np.vstack(   (allExamples, exampleGame)   )\n",
    "\n",
    "\n",
    "        # -------- PRINT STATS ------------\n",
    "        avg_mean, avg_median = np.mean(accepted_scores), np.median(accepted_scores)\n",
    "        print('Average accepted score: ', avg_mean)\n",
    "        print('Median score for accepted scores: ', avg_median)\n",
    "        print(Counter(accepted_scores))\n",
    "        print(len(accepted_scores))\n",
    "\n",
    "        return allExamples, avg_mean, avg_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Policy (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(4, 128)\n",
    "        self.l2 = nn.Linear(128, 256)\n",
    "        self.l3 = nn.Linear(256, 128)\n",
    "        self.l4 = nn.Linear(128, 32)\n",
    "        \n",
    "        self.dp = nn.Dropout(p = args.dropout)  # Suragnair used 0.3\n",
    "        self.a1 = nn.Linear(32, 2)    # want an action vector output: [log(prob right), log(prob left)]\n",
    "        self.v1 = nn.Linear(32, 32)\n",
    "        self.v2 = nn.Linear(32, 1)    # Output the expected return\n",
    "\n",
    "    def forward(self, obs):\n",
    "        #in_size = x.size(0)\n",
    "        x = F.relu(self.dp(self.l1(obs)))\n",
    "        x = F.relu(self.dp(self.l2(x)))\n",
    "        x = F.relu(self.dp(self.l3(x)))\n",
    "        x = F.relu(self.dp(self.l4(x)))\n",
    "        \n",
    "        #x = x.view(in_size, -1)  # flatten the tensor\n",
    "        a = self.a1(self.dp(x))\n",
    "        action_probs = F.log_softmax(a, dim = -1)    # choose the dimension such that we get something like \n",
    "                                                     # [exp(-0.6723) +  exp(-0.7144)] = 1 for the output\n",
    "        v = self.v2(self.dp(self.v1(x)))  # get a linear value for the expected return\n",
    "        return action_probs, v                      \n",
    "    \n",
    "    \n",
    "    def train_model(self, examples):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        action_loss, value_loss, accuracy = [], [], []\n",
    "\n",
    "        # ------------- CONVERT TO CORRECT DATA TYPE ----------------\n",
    "        gpu = torch.device(\"cpu\")\n",
    "        states = torch.tensor(  examples[:, 0:4] ,  dtype = torch.float)       #reshapes into a (23002, 4) array\n",
    "        target_actions = torch.tensor(  examples[:, 4], dtype = torch.long)    #reshapes into a (23002, 2) array \n",
    "        target_returns = torch.tensor(  examples[:, 5],  dtype = torch.float)         \n",
    "\n",
    "        #if args.cuda:  #if we're using the GPU:\n",
    "        #    states, target_actions, target_returns = states.contiguous().cuda(), target_actions.contiguous().cuda(), target_returns.contiguous().cuda()\n",
    "        #states, target_pis, target_vs = Variable(states), Variable(target_actions), Variable(target_returns)\n",
    "        # We should permute data before batching really. (X is a torch Variable)\n",
    "        #permutation = torch.randperm(X.size()[0])\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print('EPOCH ::: ' + str(epoch+1))\n",
    "            self.train()     # set module in training mode\n",
    "            batch_idx = 0\n",
    "            \n",
    "            for index in range(0, len(target_returns) - args.batch_size, args.batch_size):        \n",
    "\n",
    "                # -------- GET BATCHES -----------\n",
    "                #indices = permutation[i:i+batch_size] # [1, 2, 3, 4, 5]  -> [3, 2, 5, 1, 4]\n",
    "                #target_returns = np.shuffle(target_returns)\n",
    "                batch_idx = int(index / args.batch_size) + 1 #add one so stats print properly\n",
    "                batch_states = states[index : index+args.batch_size] # torch.Size([64, 4])\n",
    "                batch_actions = target_actions[index : index+args.batch_size] # torch.Size([64])\n",
    "                batch_returns = target_returns[index: index+args.batch_size] # torch.Size([64])\n",
    "\n",
    "                # -------------------- FEED FORWARD ---------------------- \n",
    "                pred_actions, pred_return = self.forward(batch_states) # torch.Size([64, 2]) and torch.Size([64, 1])\n",
    "                batch_NumWrong = torch.abs(torch.argmax(pred_actions, dim = 1) - batch_actions).sum()\n",
    "            \n",
    "                a_loss = F.nll_loss(pred_actions, batch_actions, reduction = 'elementwise_mean')*args.pareto #standard is \"elementwise_mean\"\n",
    "                \n",
    "                #print(pred_actions.detach(), batch_actions.detach(), a_loss.detach())\n",
    "                \n",
    "                # Suragnair uses tanh for state_values, but their values are E[win] = [-1, 1] where -1 = loss\n",
    "                # Here we are using the length of time that we have been \"up\"\n",
    "                #v_loss = F.binary_cross_entropy(torch.sigmoid(pred_return[:, 0]), torch.sigmoid(batch_returns))\n",
    "                v_loss = F.mse_loss(pred_return[:, 0], batch_returns, reduction = 'elementwise_mean')\n",
    "\n",
    "                action_loss.append(a_loss);    value_loss.append(v_loss)\n",
    "                tot_loss = a_loss + v_loss\n",
    "\n",
    "                # ----------- COMPUTE GRADS AND BACKPROP ----------------\n",
    "                optimizer.zero_grad()\n",
    "                tot_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --------- PRINT STATS --------------\n",
    "                # Get array of predicted actions and compare with target actions to compute accuracy\n",
    "                \n",
    "                accuracy.append(  1 - (batch_NumWrong.detach().numpy()) / args.batch_size    ) #counts the different ones\n",
    "                if batch_idx % 8 == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tA-Loss: {:.4f}, V-Loss: {:.4f}\\tAccuracy: {:.5f}'.format(\n",
    "                            epoch+1, \n",
    "                            batch_idx * args.batch_size, \n",
    "                            states.size()[0],\n",
    "                            100 * batch_idx * args.batch_size / states.size()[0], \n",
    "                            a_loss,\n",
    "                            v_loss,\n",
    "                            accuracy[batch_idx - 1])\n",
    "\n",
    "                     )\n",
    "\n",
    "        return action_loss, value_loss, accuracy # removed self?\n",
    "    \n",
    "    def test(self, render = False):\n",
    "        self.eval()\n",
    "        scores, expected_scores, choices = [], np.zeros(args.goal_steps), []\n",
    "\n",
    "        # ------- PLAY SOME TEST GAMES ----------\n",
    "        for each_game in range(10):\n",
    "            env.reset()\n",
    "            score, E_score = 0, []\n",
    "            game_memory, prev_obs = [], []\n",
    "\n",
    "            for _ in range(args.goal_steps):    # play up to (200) frames\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                # ----- GENERATE AN ACTION -------\n",
    "                if len(prev_obs)==0:    # start by taking a random action\n",
    "                    action = env.action_space.sample()   \n",
    "\n",
    "                else:                   # After that take the best predicted action by the neural net\n",
    "                    x = torch.tensor(   prev_obs,   dtype = torch.float    )\n",
    "                    action_prob, e_score = self.forward(x)\n",
    "                    action = np.argmax(   action_prob.detach().numpy()   )\n",
    "                    E_score.append(   e_score.detach().numpy()   )  # see how the game updates it expected score as we move through\n",
    "\n",
    "                new_observation, reward, done, info = env.step(action)\n",
    "                prev_obs = new_observation\n",
    "\n",
    "                # ----- RECORD RESULTS -------\n",
    "                choices.append(action)   # just so we can work out the ratio of what we're predicting\n",
    "\n",
    "                game_memory.append([new_observation, action])\n",
    "                score += reward\n",
    "                if done: break\n",
    "\n",
    "            scores.append(score)    # Record the score of each game\n",
    "            padding = np.zeros(int(args.goal_steps - score + 1), dtype = int)\n",
    "            E_score = np.append([np.array(E_score)], [padding])\n",
    "            expected_scores = np.vstack((expected_scores, E_score))\n",
    "\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('choice 1 (right): {:.4f}  choice 0 (left): {:.4f}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "        print(Counter(scores))\n",
    "\n",
    "        x = np.linspace(1, len(expected_scores[0]), num = len(expected_scores[0]))\n",
    "        plt.plot(x, expected_scores[1])\n",
    "        plt.plot(x, expected_scores[3])\n",
    "        plt.xlabel(\"Steps taken\"); plt.ylabel(\"Expected Return (steps until failure)\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score:  77.20748299319727\n",
      "Median score for accepted scores:  73.5\n",
      "Counter({68.0: 26, 66.0: 21, 65.0: 21, 67.0: 19, 70.0: 16, 75.0: 15, 73.0: 14, 76.0: 12, 71.0: 11, 69.0: 10, 72.0: 9, 77.0: 9, 79.0: 9, 74.0: 8, 86.0: 8, 78.0: 7, 81.0: 7, 82.0: 6, 80.0: 5, 87.0: 5, 83.0: 5, 85.0: 5, 84.0: 4, 93.0: 3, 109.0: 3, 100.0: 3, 89.0: 3, 92.0: 2, 90.0: 2, 106.0: 2, 96.0: 2, 121.0: 2, 91.0: 2, 88.0: 2, 102.0: 2, 111.0: 2, 97.0: 2, 113.0: 1, 129.0: 1, 136.0: 1, 101.0: 1, 137.0: 1, 126.0: 1, 105.0: 1, 94.0: 1, 103.0: 1, 104.0: 1})\n",
      "294\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/22699 (2%)]\tA-Loss: 3470.0549, V-Loss: 1425.8994\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [1024/22699 (5%)]\tA-Loss: 3471.0723, V-Loss: 1465.5156\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [1536/22699 (7%)]\tA-Loss: 3482.7307, V-Loss: 1650.8516\tAccuracy: 0.43750\n",
      "Train Epoch: 1 [2048/22699 (9%)]\tA-Loss: 3453.8408, V-Loss: 2449.5522\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [2560/22699 (11%)]\tA-Loss: 3413.3325, V-Loss: 3959.0840\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [3072/22699 (14%)]\tA-Loss: 3593.3787, V-Loss: 2025.9890\tAccuracy: 0.45312\n",
      "Train Epoch: 1 [3584/22699 (16%)]\tA-Loss: 3409.8374, V-Loss: 1419.6074\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [4096/22699 (18%)]\tA-Loss: 3409.6741, V-Loss: 1433.7617\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [4608/22699 (20%)]\tA-Loss: 3468.8403, V-Loss: 1593.8309\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [5120/22699 (23%)]\tA-Loss: 3335.0461, V-Loss: 1692.9128\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [5632/22699 (25%)]\tA-Loss: 3374.1016, V-Loss: 1859.1085\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [6144/22699 (27%)]\tA-Loss: 3306.3064, V-Loss: 1854.3976\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [6656/22699 (29%)]\tA-Loss: 3304.6448, V-Loss: 1345.6995\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [7168/22699 (32%)]\tA-Loss: 3607.0007, V-Loss: 1687.5088\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [7680/22699 (34%)]\tA-Loss: 3385.7324, V-Loss: 8577.5869\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [8192/22699 (36%)]\tA-Loss: 3512.6116, V-Loss: 2746.0396\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [8704/22699 (38%)]\tA-Loss: 3364.1255, V-Loss: 1359.2029\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [9216/22699 (41%)]\tA-Loss: 3351.9348, V-Loss: 2450.2729\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [9728/22699 (43%)]\tA-Loss: 3818.4392, V-Loss: 635.7368\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [10240/22699 (45%)]\tA-Loss: 3491.8965, V-Loss: 522.1700\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [10752/22699 (47%)]\tA-Loss: 3547.7200, V-Loss: 535.1880\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [11264/22699 (50%)]\tA-Loss: 3691.5476, V-Loss: 693.2455\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [11776/22699 (52%)]\tA-Loss: 3393.5469, V-Loss: 618.3275\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [12288/22699 (54%)]\tA-Loss: 3435.7649, V-Loss: 618.2833\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [12800/22699 (56%)]\tA-Loss: 3469.8811, V-Loss: 802.6971\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [13312/22699 (59%)]\tA-Loss: 3561.5332, V-Loss: 540.6598\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [13824/22699 (61%)]\tA-Loss: 3549.1091, V-Loss: 957.0393\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [14336/22699 (63%)]\tA-Loss: 3276.1609, V-Loss: 455.8910\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [14848/22699 (65%)]\tA-Loss: 3432.5623, V-Loss: 401.5970\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [15360/22699 (68%)]\tA-Loss: 3658.7097, V-Loss: 633.6073\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [15872/22699 (70%)]\tA-Loss: 3375.3347, V-Loss: 348.9838\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [16384/22699 (72%)]\tA-Loss: 3404.2002, V-Loss: 464.0551\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [16896/22699 (74%)]\tA-Loss: 3383.2908, V-Loss: 606.4800\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [17408/22699 (77%)]\tA-Loss: 3603.0847, V-Loss: 785.2183\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [17920/22699 (79%)]\tA-Loss: 3496.5647, V-Loss: 398.0087\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [18432/22699 (81%)]\tA-Loss: 3543.6899, V-Loss: 426.6332\tAccuracy: 0.46875\n",
      "Train Epoch: 1 [18944/22699 (83%)]\tA-Loss: 3333.9546, V-Loss: 531.8433\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [19456/22699 (86%)]\tA-Loss: 3349.9390, V-Loss: 332.7813\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [19968/22699 (88%)]\tA-Loss: 3386.9434, V-Loss: 280.6387\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [20480/22699 (90%)]\tA-Loss: 3354.7053, V-Loss: 310.2933\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [20992/22699 (92%)]\tA-Loss: 3385.7668, V-Loss: 383.7760\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [21504/22699 (95%)]\tA-Loss: 3324.1982, V-Loss: 304.4629\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [22016/22699 (97%)]\tA-Loss: 3444.5627, V-Loss: 260.5920\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [22528/22699 (99%)]\tA-Loss: 3333.9160, V-Loss: 347.6170\tAccuracy: 0.53125\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/34673 (1%)]\tA-Loss: 3444.4153, V-Loss: 9063.3057\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1024/34673 (3%)]\tA-Loss: 3435.0144, V-Loss: 9967.5537\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [1536/34673 (4%)]\tA-Loss: 3465.1775, V-Loss: 3997.6228\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [2048/34673 (6%)]\tA-Loss: 3370.6035, V-Loss: 4862.7871\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [2560/34673 (7%)]\tA-Loss: 3449.4248, V-Loss: 8759.9541\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [3072/34673 (9%)]\tA-Loss: 3267.2822, V-Loss: 7004.0957\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [3584/34673 (10%)]\tA-Loss: 3352.3467, V-Loss: 13217.5850\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [4096/34673 (12%)]\tA-Loss: 3005.7925, V-Loss: 7825.9985\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [4608/34673 (13%)]\tA-Loss: 2981.7217, V-Loss: 15160.0850\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [5120/34673 (15%)]\tA-Loss: 3168.5173, V-Loss: 10160.8486\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [5632/34673 (16%)]\tA-Loss: 3112.1067, V-Loss: 8371.9365\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [6144/34673 (18%)]\tA-Loss: 2881.8020, V-Loss: 1503.3381\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [6656/34673 (19%)]\tA-Loss: 2799.8621, V-Loss: 9596.7314\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [7168/34673 (21%)]\tA-Loss: 4204.0679, V-Loss: 4178.8491\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [7680/34673 (22%)]\tA-Loss: 4012.1741, V-Loss: 562.1962\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [8192/34673 (24%)]\tA-Loss: 4206.9897, V-Loss: 8461.7393\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [8704/34673 (25%)]\tA-Loss: 3292.1580, V-Loss: 789.3109\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [9216/34673 (27%)]\tA-Loss: 3069.1123, V-Loss: 733.2420\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [9728/34673 (28%)]\tA-Loss: 3845.1465, V-Loss: 1217.7499\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [10240/34673 (30%)]\tA-Loss: 3553.0059, V-Loss: 1421.2618\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [10752/34673 (31%)]\tA-Loss: 3066.8208, V-Loss: 274.5001\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [11264/34673 (32%)]\tA-Loss: 3199.6577, V-Loss: 1010.0095\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [11776/34673 (34%)]\tA-Loss: 3254.4717, V-Loss: 332.5765\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [12288/34673 (35%)]\tA-Loss: 3323.7581, V-Loss: 384.6595\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [12800/34673 (37%)]\tA-Loss: 3179.3640, V-Loss: 1043.1626\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [13312/34673 (38%)]\tA-Loss: 3116.0786, V-Loss: 4029.8833\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [13824/34673 (40%)]\tA-Loss: 3029.8721, V-Loss: 339.2360\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [14336/34673 (41%)]\tA-Loss: 3266.2791, V-Loss: 1506.2617\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [14848/34673 (43%)]\tA-Loss: 2996.3506, V-Loss: 459.5501\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [15360/34673 (44%)]\tA-Loss: 2964.6882, V-Loss: 423.3289\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [15872/34673 (46%)]\tA-Loss: 3276.1348, V-Loss: 627.5644\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [16384/34673 (47%)]\tA-Loss: 2828.9944, V-Loss: 377.9946\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [16896/34673 (49%)]\tA-Loss: 2643.5796, V-Loss: 1699.4491\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [17408/34673 (50%)]\tA-Loss: 3246.3845, V-Loss: 253.2648\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [17920/34673 (52%)]\tA-Loss: 3129.4470, V-Loss: 1131.6473\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [18432/34673 (53%)]\tA-Loss: 3258.9060, V-Loss: 2285.1113\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [18944/34673 (55%)]\tA-Loss: 2767.3606, V-Loss: 643.8702\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [19456/34673 (56%)]\tA-Loss: 3265.6548, V-Loss: 603.9495\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [19968/34673 (58%)]\tA-Loss: 2931.3718, V-Loss: 241.8015\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [20480/34673 (59%)]\tA-Loss: 3133.9321, V-Loss: 1017.0751\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [20992/34673 (61%)]\tA-Loss: 3030.4143, V-Loss: 290.7358\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [21504/34673 (62%)]\tA-Loss: 3119.3325, V-Loss: 267.2594\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [22016/34673 (63%)]\tA-Loss: 3262.7454, V-Loss: 1061.2557\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [22528/34673 (65%)]\tA-Loss: 3271.2698, V-Loss: 292.1023\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [23040/34673 (66%)]\tA-Loss: 2853.7942, V-Loss: 804.8277\tAccuracy: 0.68750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23552/34673 (68%)]\tA-Loss: 3078.6943, V-Loss: 2833.7905\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [24064/34673 (69%)]\tA-Loss: 3640.5464, V-Loss: 870.3694\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [24576/34673 (71%)]\tA-Loss: 2589.7527, V-Loss: 471.0717\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [25088/34673 (72%)]\tA-Loss: 2942.8425, V-Loss: 1012.8439\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [25600/34673 (74%)]\tA-Loss: 3368.2498, V-Loss: 432.7799\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [26112/34673 (75%)]\tA-Loss: 3148.1445, V-Loss: 2324.0513\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [26624/34673 (77%)]\tA-Loss: 2927.0027, V-Loss: 616.2280\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [27136/34673 (78%)]\tA-Loss: 3087.7937, V-Loss: 1489.8596\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [27648/34673 (80%)]\tA-Loss: 2946.1401, V-Loss: 1547.0839\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [28160/34673 (81%)]\tA-Loss: 3154.7424, V-Loss: 540.0237\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [28672/34673 (83%)]\tA-Loss: 2952.9604, V-Loss: 413.6924\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [29184/34673 (84%)]\tA-Loss: 2782.4878, V-Loss: 666.5377\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [29696/34673 (86%)]\tA-Loss: 3170.0442, V-Loss: 285.0476\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [30208/34673 (87%)]\tA-Loss: 2818.3276, V-Loss: 406.2885\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [30720/34673 (89%)]\tA-Loss: 2971.7617, V-Loss: 296.5099\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [31232/34673 (90%)]\tA-Loss: 2618.3064, V-Loss: 286.7878\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [31744/34673 (92%)]\tA-Loss: 2891.7009, V-Loss: 487.5279\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [32256/34673 (93%)]\tA-Loss: 3239.4832, V-Loss: 781.8721\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [32768/34673 (95%)]\tA-Loss: 3030.1074, V-Loss: 352.0677\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [33280/34673 (96%)]\tA-Loss: 2791.0747, V-Loss: 679.8937\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [33792/34673 (97%)]\tA-Loss: 2513.7090, V-Loss: 2557.2437\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [34304/34673 (99%)]\tA-Loss: 3182.8459, V-Loss: 897.6923\tAccuracy: 0.59375\n",
      "Average accepted score:  138.692\n",
      "Median score for accepted scores:  137.0\n",
      "Counter({200.0: 17, 118.0: 8, 136.0: 7, 122.0: 6, 153.0: 6, 145.0: 5, 142.0: 5, 147.0: 5, 175.0: 4, 119.0: 4, 112.0: 4, 143.0: 4, 120.0: 4, 135.0: 4, 107.0: 4, 117.0: 4, 125.0: 4, 137.0: 4, 144.0: 4, 159.0: 4, 154.0: 4, 138.0: 4, 133.0: 4, 146.0: 3, 160.0: 3, 128.0: 3, 98.0: 3, 129.0: 3, 149.0: 3, 124.0: 3, 108.0: 3, 105.0: 3, 139.0: 3, 190.0: 3, 163.0: 3, 116.0: 3, 148.0: 3, 166.0: 3, 113.0: 3, 152.0: 3, 104.0: 3, 155.0: 2, 97.0: 2, 131.0: 2, 127.0: 2, 114.0: 2, 89.0: 2, 165.0: 2, 134.0: 2, 84.0: 2, 173.0: 2, 161.0: 2, 109.0: 2, 171.0: 2, 121.0: 2, 141.0: 2, 140.0: 2, 167.0: 2, 110.0: 2, 132.0: 2, 87.0: 2, 126.0: 2, 164.0: 1, 111.0: 1, 188.0: 1, 174.0: 1, 181.0: 1, 67.0: 1, 179.0: 1, 58.0: 1, 130.0: 1, 158.0: 1, 106.0: 1, 183.0: 1, 180.0: 1, 157.0: 1, 150.0: 1, 168.0: 1, 95.0: 1, 102.0: 1, 156.0: 1, 162.0: 1, 172.0: 1, 151.0: 1, 53.0: 1, 81.0: 1, 99.0: 1, 123.0: 1, 72.0: 1, 169.0: 1, 170.0: 1, 100.0: 1, 101.0: 1, 68.0: 1, 182.0: 1, 115.0: 1, 178.0: 1})\n",
      "Current Policy:  77.20748299319727 73.5\n",
      "Policy Updated!\n",
      "New Policy:  138.692 137.0\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/42417 (1%)]\tA-Loss: 3446.7817, V-Loss: 7954.5972\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [1024/42417 (2%)]\tA-Loss: 3445.2871, V-Loss: 11129.2949\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1536/42417 (4%)]\tA-Loss: 3370.6426, V-Loss: 4679.2300\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [2048/42417 (5%)]\tA-Loss: 3379.1370, V-Loss: 3729.8960\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [2560/42417 (6%)]\tA-Loss: 3245.7505, V-Loss: 4814.0737\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [3072/42417 (7%)]\tA-Loss: 3010.1875, V-Loss: 19952.9395\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [3584/42417 (8%)]\tA-Loss: 2967.5923, V-Loss: 26795.4824\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [4096/42417 (10%)]\tA-Loss: 2803.7534, V-Loss: 7188.6357\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [4608/42417 (11%)]\tA-Loss: 3202.5122, V-Loss: 1460.0500\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [5120/42417 (12%)]\tA-Loss: 2633.4126, V-Loss: 9120.7334\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [5632/42417 (13%)]\tA-Loss: 4438.8770, V-Loss: 1396.9899\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [6144/42417 (14%)]\tA-Loss: 3007.7979, V-Loss: 6860.1270\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [6656/42417 (16%)]\tA-Loss: 3375.6892, V-Loss: 21575.0938\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [7168/42417 (17%)]\tA-Loss: 2582.4800, V-Loss: 9636.0420\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [7680/42417 (18%)]\tA-Loss: 3305.2795, V-Loss: 12832.9229\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [8192/42417 (19%)]\tA-Loss: 2865.9453, V-Loss: 518.7100\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [8704/42417 (21%)]\tA-Loss: 8853.6172, V-Loss: 5425.6816\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [9216/42417 (22%)]\tA-Loss: 4271.6152, V-Loss: 1353.9106\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [9728/42417 (23%)]\tA-Loss: 2709.1660, V-Loss: 3876.5862\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [10240/42417 (24%)]\tA-Loss: 3612.6387, V-Loss: 1080.5115\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [10752/42417 (25%)]\tA-Loss: 2873.2273, V-Loss: 2942.0718\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [11264/42417 (27%)]\tA-Loss: 2813.2202, V-Loss: 588.7404\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [11776/42417 (28%)]\tA-Loss: 2417.9492, V-Loss: 949.3428\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [12288/42417 (29%)]\tA-Loss: 2620.1519, V-Loss: 668.3273\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [12800/42417 (30%)]\tA-Loss: 3013.1179, V-Loss: 3925.8252\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [13312/42417 (31%)]\tA-Loss: 2550.0574, V-Loss: 1822.8792\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [13824/42417 (33%)]\tA-Loss: 2560.7136, V-Loss: 5403.6899\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [14336/42417 (34%)]\tA-Loss: 3199.4951, V-Loss: 1700.6095\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [14848/42417 (35%)]\tA-Loss: 2724.7043, V-Loss: 316.7813\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [15360/42417 (36%)]\tA-Loss: 2380.1716, V-Loss: 714.8883\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [15872/42417 (37%)]\tA-Loss: 2699.4890, V-Loss: 2627.7961\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [16384/42417 (39%)]\tA-Loss: 2287.0239, V-Loss: 2494.7417\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [16896/42417 (40%)]\tA-Loss: 2433.3828, V-Loss: 758.7958\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [17408/42417 (41%)]\tA-Loss: 2916.0000, V-Loss: 4996.8525\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [17920/42417 (42%)]\tA-Loss: 2475.1387, V-Loss: 1443.9426\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [18432/42417 (43%)]\tA-Loss: 2867.5178, V-Loss: 311.6948\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [18944/42417 (45%)]\tA-Loss: 1958.8695, V-Loss: 684.6990\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [19456/42417 (46%)]\tA-Loss: 2305.6289, V-Loss: 655.2545\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [19968/42417 (47%)]\tA-Loss: 2688.3018, V-Loss: 728.3928\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [20480/42417 (48%)]\tA-Loss: 1822.2699, V-Loss: 408.7646\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [20992/42417 (49%)]\tA-Loss: 1881.9928, V-Loss: 2314.5234\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [21504/42417 (51%)]\tA-Loss: 2467.2546, V-Loss: 2104.4548\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [22016/42417 (52%)]\tA-Loss: 1779.6134, V-Loss: 6074.8926\tAccuracy: 0.90625\n",
      "Train Epoch: 1 [22528/42417 (53%)]\tA-Loss: 2589.0515, V-Loss: 663.5663\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [23040/42417 (54%)]\tA-Loss: 3579.1934, V-Loss: 1075.1840\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [23552/42417 (56%)]\tA-Loss: 2709.9731, V-Loss: 1904.9733\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [24064/42417 (57%)]\tA-Loss: 2791.1287, V-Loss: 363.5653\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [24576/42417 (58%)]\tA-Loss: 2790.0916, V-Loss: 540.6860\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [25088/42417 (59%)]\tA-Loss: 2614.8755, V-Loss: 4677.8354\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [25600/42417 (60%)]\tA-Loss: 2894.9368, V-Loss: 353.6169\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [26112/42417 (62%)]\tA-Loss: 2003.0847, V-Loss: 755.6236\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [26624/42417 (63%)]\tA-Loss: 3117.2095, V-Loss: 1274.3463\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [27136/42417 (64%)]\tA-Loss: 2015.2673, V-Loss: 1337.4706\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [27648/42417 (65%)]\tA-Loss: 1887.3058, V-Loss: 1123.9783\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [28160/42417 (66%)]\tA-Loss: 1813.0022, V-Loss: 694.7982\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [28672/42417 (68%)]\tA-Loss: 2131.9407, V-Loss: 1465.9639\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [29184/42417 (69%)]\tA-Loss: 2731.0706, V-Loss: 3389.7034\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [29696/42417 (70%)]\tA-Loss: 2566.4700, V-Loss: 2506.4688\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [30208/42417 (71%)]\tA-Loss: 2446.6592, V-Loss: 2279.7195\tAccuracy: 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [30720/42417 (72%)]\tA-Loss: 2251.5137, V-Loss: 441.7181\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [31232/42417 (74%)]\tA-Loss: 2302.1750, V-Loss: 784.8580\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [31744/42417 (75%)]\tA-Loss: 2374.5681, V-Loss: 429.9434\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [32256/42417 (76%)]\tA-Loss: 2736.6628, V-Loss: 1375.1949\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [32768/42417 (77%)]\tA-Loss: 3028.9241, V-Loss: 2365.8154\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [33280/42417 (78%)]\tA-Loss: 3014.1392, V-Loss: 606.5773\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [33792/42417 (80%)]\tA-Loss: 2639.4424, V-Loss: 617.8184\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [34304/42417 (81%)]\tA-Loss: 1971.4196, V-Loss: 1286.9907\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [34816/42417 (82%)]\tA-Loss: 3024.5103, V-Loss: 723.8754\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [35328/42417 (83%)]\tA-Loss: 2176.9878, V-Loss: 466.9935\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [35840/42417 (84%)]\tA-Loss: 2137.1692, V-Loss: 590.5755\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [36352/42417 (86%)]\tA-Loss: 3350.3115, V-Loss: 4409.6865\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [36864/42417 (87%)]\tA-Loss: 2920.8037, V-Loss: 676.9544\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [37376/42417 (88%)]\tA-Loss: 2533.5479, V-Loss: 408.6810\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [37888/42417 (89%)]\tA-Loss: 1922.0208, V-Loss: 950.2231\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [38400/42417 (91%)]\tA-Loss: 2556.9854, V-Loss: 1827.2961\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [38912/42417 (92%)]\tA-Loss: 2237.6328, V-Loss: 2326.8103\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [39424/42417 (93%)]\tA-Loss: 2688.7812, V-Loss: 1717.7145\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [39936/42417 (94%)]\tA-Loss: 2117.5549, V-Loss: 4381.5459\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [40448/42417 (95%)]\tA-Loss: 2062.3635, V-Loss: 3405.5598\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [40960/42417 (97%)]\tA-Loss: 1971.1174, V-Loss: 1404.3374\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [41472/42417 (98%)]\tA-Loss: 1983.2678, V-Loss: 3778.4897\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [41984/42417 (99%)]\tA-Loss: 2766.0618, V-Loss: 1090.6118\tAccuracy: 0.71875\n",
      "Average accepted score:  154.18\n",
      "Median score for accepted scores:  150.0\n",
      "Counter({200.0: 97, 142.0: 10, 153.0: 10, 136.0: 9, 139.0: 9, 144.0: 9, 147.0: 9, 148.0: 9, 132.0: 9, 118.0: 8, 154.0: 8, 146.0: 7, 175.0: 7, 143.0: 7, 137.0: 7, 159.0: 7, 145.0: 6, 122.0: 6, 160.0: 6, 129.0: 6, 149.0: 6, 138.0: 6, 140.0: 6, 131.0: 5, 119.0: 5, 127.0: 5, 120.0: 5, 135.0: 5, 165.0: 5, 117.0: 5, 173.0: 5, 163.0: 5, 168.0: 5, 141.0: 5, 126.0: 5, 178.0: 5, 112.0: 4, 128.0: 4, 181.0: 4, 107.0: 4, 124.0: 4, 125.0: 4, 161.0: 4, 150.0: 4, 133.0: 4, 162.0: 4, 151.0: 4, 152.0: 4, 170.0: 4, 187.0: 4, 155.0: 3, 164.0: 3, 114.0: 3, 188.0: 3, 98.0: 3, 134.0: 3, 179.0: 3, 108.0: 3, 105.0: 3, 190.0: 3, 183.0: 3, 171.0: 3, 116.0: 3, 167.0: 3, 166.0: 3, 113.0: 3, 172.0: 3, 104.0: 3, 169.0: 3, 185.0: 3, 184.0: 3, 191.0: 3, 97.0: 2, 89.0: 2, 84.0: 2, 130.0: 2, 158.0: 2, 180.0: 2, 109.0: 2, 121.0: 2, 110.0: 2, 87.0: 2, 123.0: 2, 186.0: 2, 111.0: 1, 174.0: 1, 67.0: 1, 58.0: 1, 106.0: 1, 157.0: 1, 95.0: 1, 102.0: 1, 156.0: 1, 53.0: 1, 81.0: 1, 99.0: 1, 72.0: 1, 100.0: 1, 101.0: 1, 68.0: 1, 182.0: 1, 115.0: 1, 196.0: 1, 198.0: 1, 177.0: 1, 195.0: 1, 176.0: 1, 193.0: 1, 197.0: 1})\n",
      "Current Policy:  138.692 137.0\n",
      "Policy Updated!\n",
      "New Policy:  154.18 150.0\n"
     ]
    }
   ],
   "source": [
    "test = Controller(Net())\n",
    "best_model = test.policyIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 165.6\n",
      "choice 1 (right): 0.4752  choice 0 (left): 0.5248\n",
      "Counter({200.0: 2, 147.0: 2, 191.0: 1, 143.0: 1, 159.0: 1, 141.0: 1, 162.0: 1, 166.0: 1})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.test(render = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suragnair's MCTS Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "\n",
    "    def __init__(self, nnet):\n",
    "        self.nnet = nnet    #fuction handle\n",
    "        self.c_puct = 0.1\n",
    "        self.Qsa = {}       # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores #times edge s,a was visited\n",
    "        self.Ns = {}        # stores #times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "    def search(self, s, reward, done):\n",
    "        # ---------------- TERMINAL STATE ---------------\n",
    "        if done == True:\n",
    "            return reward\n",
    "\n",
    "        # ------------- EXPLORING FROM A LEAF NODE ----------------------\n",
    "        #check if the state has a policy from it yet, if not then its a leaf\n",
    "        if s not in self.Ps:\n",
    "            self.Ps[s], v = self.nnet.predict(s)\n",
    "            \n",
    "            #check if the neural net has assigned a +ve prob to any policy\n",
    "             \n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s    # renormalize\n",
    "            else:\n",
    "                # if they were all zero then they are equally probable: (this shouldn't usually happen)\n",
    "                # NB! All valid moves may = 0 if NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                print(\"All valid moves were masked, do workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "        \n",
    "\n",
    "        # ------------- GET BEST ACTION -----------------------------\n",
    "        # search through the valid actions and update the UCB for all actions then update best acions\n",
    "        max_u, best_a = -float(\"inf\"), -1\n",
    "        for a in range(1):\n",
    "            if (s,a) in self.Qsa:\n",
    "                u = self.Qsa[(s,a)] + self.cpuct*self.Ps[s][a]*np.sqrt(self.Ns[s])/(1+self.Nsa[(s,a)])\n",
    "            else:\n",
    "                u = self.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s] + 1e-8)     # Q = 0 ?\n",
    "            \n",
    "            if u > max_u:\n",
    "                max_u = u\n",
    "                best_a = a\n",
    "        a = best_a\n",
    "\n",
    "        \n",
    "        # ----------- RECURSION TO NEXT STATE ------------------------\n",
    "        sp, reward, done, info = env.step(a)\n",
    "        v = self.search(sp, reward, done)\n",
    "        \n",
    "\n",
    "        # ------------ BACKUP Q-VALUES AND N_VISITED -----------------\n",
    "        # after we reach the terminal condition then the stack unwinds and we\n",
    "        # propagate up the tree backing up Q and N as we go\n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)]*self.Qsa[(s,a)] + v)/(self.Nsa[(s,a)]+1)\n",
    "            self.Nsa[(s,a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
