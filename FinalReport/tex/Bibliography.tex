\documentclass[../main.tex]{subfiles}
\begin{document}
\stepcounter{chapter} % for some reason bibliography has the same number as the previous chapter...
\renewcommand{\bibname}{References}
\addcontentsline{toc}{chapter}{References}
\begin{thebibliography}{9}
    \bibitem{4f2}
        M.C. Smith, I Lestas,
        \emph{4F2: Robust and Non-Linear Control}
        Cambridge University Engineering Department, 2019

    \bibitem{4f3}
        G. Vinnicombe, K. Glover, F. Forni,
        \emph{4F3: Optimal and Predictive Control}
        Cambridge University Engineering Department, 2019

    \bibitem{4f7}
        S. Singh,
        \emph{4F7: Statistical Signal Analysis}
        Cambridge University Engineering Department, 2019

    \bibitem{History}
        Arthur E. Bryson Jr,
        \emph{Optimal Control - 1950 to 1985}.
        IEEE Control Systems, 0272-1708/95 pg.26-33, 1996.

    \bibitem{aircraftoptcont}
        I. Michael Ross, Ronald J. Proulx, and Mark Karpenko,
        \emph{Unscented Optimal Control for Space Flight}.
        ISSFD S12-5, 2014.

    \bibitem{aileronoptcont}
        Zheng Jie Wang, Shijun Guo, Wei Li,
        \emph{Modeling,Simulation and Optimal Control for an Aircraft of
        Aileron-less Folding Wing}
        WSEAS TRANSACTIONS on SYSTEMS and CONTROL, ISSN: 1991-8763, 10:3, 2008

    \bibitem{rovermpc}
        Giovanni Binet, Rainer Krenn and Alberto Bemporad,
        \emph{Model Predictive Control Applications for Planetary Rovers}.
        imtlucca, 2012.

    \bibitem{rmpc}
        Rakovi{\'{c}}, Sa{\v{s}}a,
        \emph{"Robust Model-Predictive Control}.
        Encyclopedia of Systems and Control, pg.1-11 ,2013.

    \bibitem{invpen}
        Russ Tedrake,
        \emph{Underactuated Robotics}.
        MIT OpenCourseWare, Ch.3, Spring 2009.

    \bibitem{RLintro}
        Richard S. Sutton and Andrew G. Barto,
        \emph{Reinforcement Learning: An Introduction (2nd Edition)}.
        The MIT Press, Cambridge, Massachusetts, London, England. 2018.

    \bibitem{Qlearning}
        I. Carlucho, M. De Paula, S. Villar, G. Acosta . \emph{Incremental Q-learning strategy for adaptive PID control of mobile robots}. 
        Expert Systems with Applications. 80. 10.1016, 2017

    \bibitem{RLoverview}
        Yuxi Li, 
        \emph{Deep Reinforcement Learning: An Overview}. 
        CoRR, abs/1810.06339, 2018.
    
    \bibitem{Robothand}
        Sandy H. Huang, Martina Zambelli, Jackie Kay, Murilo F. Martins, Yuval Tassa, Patrick M. Pilarski, Raia Hadsell,
        \emph{Learning Gentle Object Manipulation with Curiosity-Driven Deep Reinforcement Learning}.
        arXiv 2019.

    \bibitem{AlphaGoZero}
        David Silver, Julian Schrittwieser, Karen Simonyan et al,
        \emph{Mastering the game of Go without human knowledge}.
        Nature, vol. 550, pg.354â€“359, 2017.
    
    \bibitem{AlphaZero}
        David Silver, Thomas Hubert, Julian Schrittwieser et al, 
        \emph{A general reinforcement learning algorithm that
        masters chess, shogi and Go through self-pla}.
        Science 362:6419, pg.1140-1144, 2018.

    \bibitem{Othello}
        S. Thakoor, S. Nair and M. Jhunjhunwala,
        \emph{Learning to Play Othello Without Human Knowledge}
        Stanford University Press, 2018
        \texttt{https://github.com/suragnair/alpha-zero-general}

    \bibitem{alphastar}
        Google Deepmind,
        \emph{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}.
        \texttt{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game} 
        \texttt{-starcraft-ii/}
        
\end{thebibliography}

\end{document}