{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nA pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \\nThe system is controlled by applying a force of +1 or -1 to the cart. \\nThe pendulum starts upright, and the goal is to prevent it from falling over. \\nA reward of +1 is provided for every timestep that the pole remains upright.\\nThe episode ends when the pole is more than 15 degrees from vertical, or the \\ncart moves more than 2.4 units from the center.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "''' \n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. \n",
    "The system is controlled by applying a force of +1 or -1 to the cart. \n",
    "The pendulum starts upright, and the goal is to prevent it from falling over. \n",
    "A reward of +1 is provided for every timestep that the pole remains upright.\n",
    "The episode ends when the pole is more than 15 degrees from vertical, or the \n",
    "cart moves more than 2.4 units from the center.\n",
    "'''\n",
    "\n",
    "# env.reset()    #returns an initial observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02398537 -0.04020076  0.00995269 -0.03698792]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "observation = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "args = dotdict({\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64, #256,\n",
    "    'pareto': 5000, # a factor to multiply action loss by to get optimal loss (5000 ish seems to work well)\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "    'goal_steps': 201, #200 is the limit for cart-pole\n",
    "    'score_requirement': 65,\n",
    "    'initial_games': 30000,\n",
    "    'policyUpdates': 2,    #10\n",
    "    'policyEpisodes': 250, #250\n",
    "})\n",
    "print(args.pareto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller (coach) Class: PI and Episode Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller():\n",
    "    \n",
    "    def __init__(self, nnet = None):\n",
    "        self.nnet = nnet   # the nnet \"is part of\" the controller -> composition (or aggregation?.. implemented by pointer/reference in c++)\n",
    "        #self.mcts = MCTS()\n",
    "        \n",
    "    def policyIteration(self):\n",
    "    \n",
    "        scores = np.array([])\n",
    "\n",
    "        #self.nnet = Net() # don't actually need to initiate the \"prev_nnet\", since it is defined when we create a controller object\n",
    "        init_examples, curr_mean, curr_median = initialExamples()  # Don't need to pass a model\n",
    "        a_loss, v_loss, batch_acc = self.nnet.train_model(examples = init_examples)\n",
    "\n",
    "        for i in range(args.policyUpdates):\n",
    "\n",
    "            # ----- GENERATE A NEW BATCH OF EPISODES BASED ON THE CURRENT NET----------\n",
    "            exampleBatch = []\n",
    "            for e in range(args.policyEpisodes):\n",
    "                example = self.executeEpisode()\n",
    "                scores = np.append(scores, example[0, 5])\n",
    "\n",
    "                if len(exampleBatch) == 0:\n",
    "                    exampleBatch = example\n",
    "                else:\n",
    "                    exampleBatch = np.vstack(   (exampleBatch, example)   )\n",
    "\n",
    "\n",
    "            # -------- CREATE CHALLENGER POLICY BASED ON EXAMPLES GENERATED BY PREVIOUS POLICY -------------------\n",
    "            new_nnet = Net() # create a new net to train\n",
    "            a_loss, v_loss, batch_acc = new_nnet.train_model(examples = exampleBatch)\n",
    "\n",
    "\n",
    "            # -------- PRINT STATS ON NEW POLICY -------------\n",
    "            new_mean, new_median = np.mean(scores), np.median(scores)\n",
    "            print('Average accepted score: ', new_mean)\n",
    "            print('Median score for accepted scores: ', new_median)\n",
    "            print(Counter(scores))\n",
    "            print(\"Current Policy: \", curr_mean, curr_median)\n",
    "\n",
    "            # ---------- COMPARE AND UPDATE POLICIES --------------\n",
    "            if new_mean >= curr_mean and new_median >= curr_median:\n",
    "                self.nnet = new_nnet\n",
    "                curr_mean, curr_median = new_mean, new_median\n",
    "                print(\"Policy Updated!\")\n",
    "                print(\"New Policy: \", curr_mean, curr_median)\n",
    "\n",
    "        return self.nnet\n",
    "    \n",
    "    def executeEpisode(self):\n",
    "        ''' Generate and example episode of [4 x observation(t), action(t), E[return(t)]]. \n",
    "            All values are in a (n x 6) numpy array where n is the number of steps for the \n",
    "            episode to finish or the limit of 200 steps'''\n",
    "        score = 0\n",
    "        example = np.zeros((args.goal_steps, 6) )\n",
    "        prev_observation = env.reset() # list of 4 elements\n",
    "\n",
    "        # --------- ITERATE UP TO 500 STEPS PER EPISODE -------------\n",
    "        for t in range(args.goal_steps):\n",
    "\n",
    "            # --------- GENERATE ACTION ------------\n",
    "            # We can generate random actions or actions from the previous policy (i.e. prev nnet)\n",
    "            if self.nnet == None or t == 0:\n",
    "                action = env.action_space.sample()   # choose random action (0-left or 1-right)\n",
    "            else:\n",
    "                x = torch.tensor(   prev_observation,   dtype = torch.float    )\n",
    "                action_prob, e_score = self.nnet.forward(x)\n",
    "                action = np.argmax(   action_prob.detach().numpy()   )                \n",
    "\n",
    "            observation, reward, done, info = env.step(action)\n",
    "\n",
    "            # --------- STORE STATE-ACTION PAIR + SCORE ------------\n",
    "            example[t, 0:4] = prev_observation[0:4]\n",
    "            example[t, 4:6] = [action, score]\n",
    "\n",
    "            prev_observation = np.array(observation)\n",
    "            score += reward    # +1 for every frame we haven't fallen\n",
    "\n",
    "            if done: \n",
    "                break\n",
    "\n",
    "        example[:, 5] = score - example[:, 5]    # Convert scores to E[return] \n",
    "        return example[0:int(score), :] # we only want to return the parts with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialExamples():\n",
    "        allExamples = []\n",
    "        accepted_scores = np.array([])    # just the scores that met our threshold\n",
    "        init_controller = Controller()\n",
    "        init_controller.nnet = None                 # so that executeEpisode doesn't try anything weird\n",
    "\n",
    "        # --------------- ITERATE THROUGH 10000 EPISODE ------------------\n",
    "        for _ in range(args.initial_games):\n",
    "\n",
    "            exampleGame = init_controller.executeEpisode()\n",
    "\n",
    "            # --------- SAVE EXAMPLE (EPISODE) IF (SCORE > THRESHOLD) ----------\n",
    "            # Note, it does not save the score! Therefore all episodes with score > threshold\n",
    "            # are treated equally (not the best way of doing this!)\n",
    "            if exampleGame[0, 5] >= args.score_requirement:\n",
    "\n",
    "                accepted_scores = np.append(accepted_scores, exampleGame[0, 5])\n",
    "\n",
    "                if len(allExamples) == 0:\n",
    "                    allExamples = exampleGame\n",
    "                else:\n",
    "                    allExamples = np.vstack(   (allExamples, exampleGame)   )\n",
    "\n",
    "\n",
    "        # -------- PRINT STATS ------------\n",
    "        avg_mean, avg_median = np.mean(accepted_scores), np.median(accepted_scores)\n",
    "        print('Average accepted score: ', avg_mean)\n",
    "        print('Median score for accepted scores: ', avg_median)\n",
    "        print(Counter(accepted_scores))\n",
    "        print(len(accepted_scores))\n",
    "\n",
    "        return allExamples, avg_mean, avg_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Policy (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(4, 128)\n",
    "        self.l2 = nn.Linear(128, 256)\n",
    "        self.l3 = nn.Linear(256, 128)\n",
    "        self.l4 = nn.Linear(128, 32)\n",
    "        \n",
    "        self.dp = nn.Dropout(p = args.dropout)  # Suragnair used 0.3\n",
    "        self.a1 = nn.Linear(32, 2)    # want an action vector output: [log(prob right), log(prob left)]\n",
    "        self.v1 = nn.Linear(32, 32)\n",
    "        self.v2 = nn.Linear(32, 1)    # Output the expected return\n",
    "\n",
    "    def forward(self, obs):\n",
    "        #in_size = x.size(0)\n",
    "        x = F.relu(self.dp(self.l1(obs)))\n",
    "        x = F.relu(self.dp(self.l2(x)))\n",
    "        x = F.relu(self.dp(self.l3(x)))\n",
    "        x = F.relu(self.dp(self.l4(x)))\n",
    "        \n",
    "        #x = x.view(in_size, -1)  # flatten the tensor\n",
    "        a = self.a1(self.dp(x))\n",
    "        action_probs = F.log_softmax(a, dim = -1)    # choose the dimension such that we get something like \n",
    "                                                     # [exp(-0.6723) +  exp(-0.7144)] = 1 for the output\n",
    "        v = self.v2(self.dp(self.v1(x)))  # get a linear value for the expected return\n",
    "        return action_probs, v                      \n",
    "    \n",
    "    \n",
    "    def train_model(self, examples):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        action_loss, value_loss, accuracy = [], [], []\n",
    "\n",
    "        # ------------- CONVERT TO CORRECT DATA TYPE ----------------\n",
    "        gpu = torch.device(\"cpu\")\n",
    "        states = torch.tensor(  examples[:, 0:4] ,  dtype = torch.float)       #reshapes into a (23002, 4) array\n",
    "        target_actions = torch.tensor(  examples[:, 4], dtype = torch.long)    #reshapes into a (23002, 2) array \n",
    "        target_returns = torch.tensor(  examples[:, 5],  dtype = torch.float)         \n",
    "\n",
    "        #if args.cuda:  #if we're using the GPU:\n",
    "        #    states, target_actions, target_returns = states.contiguous().cuda(), target_actions.contiguous().cuda(), target_returns.contiguous().cuda()\n",
    "        #states, target_pis, target_vs = Variable(states), Variable(target_actions), Variable(target_returns)\n",
    "        # We should permute data before batching really. (X is a torch Variable)\n",
    "        #permutation = torch.randperm(X.size()[0])\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print('EPOCH ::: ' + str(epoch+1))\n",
    "            self.train()     # set module in training mode\n",
    "            batch_idx = 0\n",
    "            \n",
    "            for index in range(0, len(target_returns) - args.batch_size, args.batch_size):        \n",
    "\n",
    "                # -------- GET BATCHES -----------\n",
    "                #indices = permutation[i:i+batch_size] # [1, 2, 3, 4, 5]  -> [3, 2, 5, 1, 4]\n",
    "                #target_returns = np.shuffle(target_returns)\n",
    "                batch_idx = int(index / args.batch_size) + 1 #add one so stats print properly\n",
    "                batch_states = states[index : index+args.batch_size] # torch.Size([64, 4])\n",
    "                batch_actions = target_actions[index : index+args.batch_size] # torch.Size([64])\n",
    "                batch_returns = target_returns[index: index+args.batch_size] # torch.Size([64])\n",
    "\n",
    "                # -------------------- FEED FORWARD ---------------------- \n",
    "                pred_actions, pred_return = self.forward(batch_states) # torch.Size([64, 2]) and torch.Size([64, 1])\n",
    "                batch_NumWrong = torch.abs(torch.argmax(pred_actions, dim = 1) - batch_actions).sum()\n",
    "            \n",
    "                a_loss = F.nll_loss(pred_actions, batch_actions, reduction = 'elementwise_mean')*args.pareto #standard is \"elementwise_mean\"\n",
    "                \n",
    "                #print(pred_actions.detach(), batch_actions.detach(), a_loss.detach())\n",
    "                \n",
    "                # Suragnair uses tanh for state_values, but their values are E[win] = [-1, 1] where -1 = loss\n",
    "                # Here we are using the length of time that we have been \"up\"\n",
    "                #v_loss = F.binary_cross_entropy(torch.sigmoid(pred_return[:, 0]), torch.sigmoid(batch_returns))\n",
    "                v_loss = F.mse_loss(pred_return[:, 0], batch_returns, reduction = 'elementwise_mean')\n",
    "\n",
    "                action_loss.append(a_loss);    value_loss.append(v_loss)\n",
    "                tot_loss = a_loss + v_loss\n",
    "\n",
    "                # ----------- COMPUTE GRADS AND BACKPROP ----------------\n",
    "                optimizer.zero_grad()\n",
    "                tot_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --------- PRINT STATS --------------\n",
    "                # Get array of predicted actions and compare with target actions to compute accuracy\n",
    "                \n",
    "                accuracy.append(  1 - (batch_NumWrong.detach().numpy()) / args.batch_size    ) #counts the different ones\n",
    "                if batch_idx % 8 == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tA-Loss: {:.4f}, V-Loss: {:.4f}\\tAccuracy: {:.5f}'.format(\n",
    "                            epoch+1, \n",
    "                            batch_idx * args.batch_size, \n",
    "                            states.size()[0],\n",
    "                            100 * batch_idx * args.batch_size / states.size()[0], \n",
    "                            a_loss,\n",
    "                            v_loss,\n",
    "                            accuracy[batch_idx - 1])\n",
    "\n",
    "                     )\n",
    "\n",
    "        return action_loss, value_loss, accuracy # removed self?\n",
    "    \n",
    "    def test(self, render = False):\n",
    "        self.eval()\n",
    "        scores, expected_scores, choices = [], np.zeros(args.goal_steps), []\n",
    "\n",
    "        # ------- PLAY SOME TEST GAMES ----------\n",
    "        for each_game in range(10):\n",
    "            env.reset()\n",
    "            score, E_score = 0, []\n",
    "            game_memory, prev_obs = [], []\n",
    "\n",
    "            for _ in range(args.goal_steps):    # play up to (200) frames\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                # ----- GENERATE AN ACTION -------\n",
    "                if len(prev_obs)==0:    # start by taking a random action\n",
    "                    action = env.action_space.sample()   \n",
    "\n",
    "                else:                   # After that take the best predicted action by the neural net\n",
    "                    x = torch.tensor(   prev_obs,   dtype = torch.float    )\n",
    "                    action_prob, e_score = self.forward(x)\n",
    "                    action = np.argmax(   action_prob.detach().numpy()   )\n",
    "                    E_score.append(   e_score.detach().numpy()   )  # see how the game updates it expected score as we move through\n",
    "\n",
    "                new_observation, reward, done, info = env.step(action)\n",
    "                prev_obs = new_observation\n",
    "\n",
    "                # ----- RECORD RESULTS -------\n",
    "                choices.append(action)   # just so we can work out the ratio of what we're predicting\n",
    "\n",
    "                game_memory.append([new_observation, action])\n",
    "                score += reward\n",
    "                if done: break\n",
    "\n",
    "            scores.append(score)    # Record the score of each game\n",
    "            padding = np.zeros(int(args.goal_steps - score + 1), dtype = int)\n",
    "            E_score = np.append([np.array(E_score)], [padding])\n",
    "            expected_scores = np.vstack((expected_scores, E_score))\n",
    "\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('choice 1 (right): {:.4f}  choice 0 (left): {:.4f}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "        print(Counter(scores))\n",
    "\n",
    "        x = np.linspace(1, len(expected_scores[0]), num = len(expected_scores[0]))\n",
    "        plt.plot(x, expected_scores[1])\n",
    "        plt.plot(x, expected_scores[3])\n",
    "        plt.xlabel(\"Steps taken\"); plt.ylabel(\"Expected Return (steps until failure)\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score:  76.34177215189874\n",
      "Median score for accepted scores:  74.0\n",
      "Counter({65.0: 35, 67.0: 25, 69.0: 18, 66.0: 18, 70.0: 15, 74.0: 14, 68.0: 12, 73.0: 12, 75.0: 12, 71.0: 11, 72.0: 11, 86.0: 10, 76.0: 10, 82.0: 10, 77.0: 9, 83.0: 9, 79.0: 9, 81.0: 8, 80.0: 7, 85.0: 7, 89.0: 6, 88.0: 5, 78.0: 5, 87.0: 4, 92.0: 4, 91.0: 3, 84.0: 3, 95.0: 2, 90.0: 2, 109.0: 2, 97.0: 2, 98.0: 2, 99.0: 2, 102.0: 2, 123.0: 1, 100.0: 1, 111.0: 1, 119.0: 1, 94.0: 1, 127.0: 1, 106.0: 1, 120.0: 1, 104.0: 1, 110.0: 1})\n",
      "316\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/24124 (2%)]\tA-Loss: 3459.2449, V-Loss: 1593.3538\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [1024/24124 (4%)]\tA-Loss: 3442.2461, V-Loss: 1496.0848\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1536/24124 (6%)]\tA-Loss: 3463.8259, V-Loss: 2257.1389\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [2048/24124 (8%)]\tA-Loss: 3379.9424, V-Loss: 1521.5530\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [2560/24124 (11%)]\tA-Loss: 3431.5027, V-Loss: 4742.9585\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [3072/24124 (13%)]\tA-Loss: 3333.1812, V-Loss: 1657.3308\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [3584/24124 (15%)]\tA-Loss: 3429.1663, V-Loss: 1560.0793\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [4096/24124 (17%)]\tA-Loss: 3464.6714, V-Loss: 1433.7982\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [4608/24124 (19%)]\tA-Loss: 3475.8201, V-Loss: 1695.7529\tAccuracy: 0.48438\n",
      "Train Epoch: 1 [5120/24124 (21%)]\tA-Loss: 3369.4111, V-Loss: 3792.0156\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [5632/24124 (23%)]\tA-Loss: 3253.5830, V-Loss: 1674.6851\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [6144/24124 (25%)]\tA-Loss: 3327.8140, V-Loss: 1923.7101\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [6656/24124 (28%)]\tA-Loss: 3754.5889, V-Loss: 1671.6558\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [7168/24124 (30%)]\tA-Loss: 3517.2722, V-Loss: 1436.9958\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [7680/24124 (32%)]\tA-Loss: 3325.3569, V-Loss: 1243.5828\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [8192/24124 (34%)]\tA-Loss: 3204.9790, V-Loss: 1702.8694\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [8704/24124 (36%)]\tA-Loss: 3390.5107, V-Loss: 1264.2733\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [9216/24124 (38%)]\tA-Loss: 3698.1833, V-Loss: 1033.2338\tAccuracy: 0.51562\n",
      "Train Epoch: 1 [9728/24124 (40%)]\tA-Loss: 3910.4265, V-Loss: 522.1024\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [10240/24124 (42%)]\tA-Loss: 3537.4658, V-Loss: 571.8994\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [10752/24124 (45%)]\tA-Loss: 3585.8982, V-Loss: 853.9519\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [11264/24124 (47%)]\tA-Loss: 3397.2412, V-Loss: 1208.6608\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [11776/24124 (49%)]\tA-Loss: 3340.3181, V-Loss: 453.1859\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [12288/24124 (51%)]\tA-Loss: 3483.8406, V-Loss: 487.9128\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [12800/24124 (53%)]\tA-Loss: 3338.5667, V-Loss: 447.1131\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [13312/24124 (55%)]\tA-Loss: 3327.4905, V-Loss: 459.8573\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [13824/24124 (57%)]\tA-Loss: 3637.4971, V-Loss: 851.6016\tAccuracy: 0.46875\n",
      "Train Epoch: 1 [14336/24124 (59%)]\tA-Loss: 3416.9368, V-Loss: 328.4202\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [14848/24124 (62%)]\tA-Loss: 3294.8416, V-Loss: 703.6655\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [15360/24124 (64%)]\tA-Loss: 3465.8169, V-Loss: 610.1578\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [15872/24124 (66%)]\tA-Loss: 3423.6931, V-Loss: 912.0195\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [16384/24124 (68%)]\tA-Loss: 3483.6157, V-Loss: 498.8727\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [16896/24124 (70%)]\tA-Loss: 3319.1921, V-Loss: 698.0288\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [17408/24124 (72%)]\tA-Loss: 3552.7781, V-Loss: 877.0279\tAccuracy: 0.53125\n",
      "Train Epoch: 1 [17920/24124 (74%)]\tA-Loss: 3382.5454, V-Loss: 449.1904\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [18432/24124 (76%)]\tA-Loss: 3754.2520, V-Loss: 925.1618\tAccuracy: 0.46875\n",
      "Train Epoch: 1 [18944/24124 (79%)]\tA-Loss: 3426.9468, V-Loss: 294.8716\tAccuracy: 0.56250\n",
      "Train Epoch: 1 [19456/24124 (81%)]\tA-Loss: 3353.6072, V-Loss: 387.8690\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [19968/24124 (83%)]\tA-Loss: 3366.0728, V-Loss: 315.0825\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [20480/24124 (85%)]\tA-Loss: 3426.0557, V-Loss: 613.2106\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [20992/24124 (87%)]\tA-Loss: 3190.3916, V-Loss: 579.7510\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [21504/24124 (89%)]\tA-Loss: 3536.2422, V-Loss: 916.1517\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [22016/24124 (91%)]\tA-Loss: 3416.4163, V-Loss: 277.9399\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [22528/24124 (93%)]\tA-Loss: 3306.9753, V-Loss: 449.9022\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [23040/24124 (96%)]\tA-Loss: 3337.7708, V-Loss: 719.4487\tAccuracy: 0.54688\n",
      "Train Epoch: 1 [23552/24124 (98%)]\tA-Loss: 3471.7427, V-Loss: 328.0684\tAccuracy: 0.57812\n",
      "Train Epoch: 1 [24064/24124 (100%)]\tA-Loss: 3245.4832, V-Loss: 175.4065\tAccuracy: 0.70312\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/43919 (1%)]\tA-Loss: 3488.4561, V-Loss: 14823.5381\tAccuracy: 0.50000\n",
      "Train Epoch: 1 [1024/43919 (2%)]\tA-Loss: 3412.9592, V-Loss: 7110.7729\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [1536/43919 (3%)]\tA-Loss: 3389.5310, V-Loss: 13850.3486\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [2048/43919 (5%)]\tA-Loss: 3330.1499, V-Loss: 14073.8701\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [2560/43919 (6%)]\tA-Loss: 3259.5974, V-Loss: 5363.1763\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [3072/43919 (7%)]\tA-Loss: 3181.7319, V-Loss: 9848.2480\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [3584/43919 (8%)]\tA-Loss: 3380.9302, V-Loss: 10731.9658\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [4096/43919 (9%)]\tA-Loss: 2850.0330, V-Loss: 20378.6133\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [4608/43919 (10%)]\tA-Loss: 3072.5161, V-Loss: 2821.0969\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [5120/43919 (12%)]\tA-Loss: 3278.3943, V-Loss: 2372.3679\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [5632/43919 (13%)]\tA-Loss: 2877.7766, V-Loss: 3973.8589\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [6144/43919 (14%)]\tA-Loss: 3134.7043, V-Loss: 11687.1982\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [6656/43919 (15%)]\tA-Loss: 3591.6504, V-Loss: 3112.5271\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [7168/43919 (16%)]\tA-Loss: 3571.3696, V-Loss: 3591.3555\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [7680/43919 (17%)]\tA-Loss: 4068.9773, V-Loss: 593.3380\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [8192/43919 (19%)]\tA-Loss: 3558.6853, V-Loss: 2386.0261\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [8704/43919 (20%)]\tA-Loss: 3959.6062, V-Loss: 7193.6514\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [9216/43919 (21%)]\tA-Loss: 2906.7629, V-Loss: 1596.0370\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [9728/43919 (22%)]\tA-Loss: 2997.7529, V-Loss: 1802.7212\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [10240/43919 (23%)]\tA-Loss: 2954.8860, V-Loss: 1199.4285\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [10752/43919 (24%)]\tA-Loss: 2862.2507, V-Loss: 9258.2842\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [11264/43919 (26%)]\tA-Loss: 2945.3640, V-Loss: 4091.9885\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [11776/43919 (27%)]\tA-Loss: 3216.9419, V-Loss: 6964.1060\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [12288/43919 (28%)]\tA-Loss: 2831.1763, V-Loss: 1031.7057\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [12800/43919 (29%)]\tA-Loss: 3048.6399, V-Loss: 2323.5442\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [13312/43919 (30%)]\tA-Loss: 2933.4871, V-Loss: 3498.8689\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [13824/43919 (31%)]\tA-Loss: 2892.9155, V-Loss: 7260.9883\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [14336/43919 (33%)]\tA-Loss: 2946.4104, V-Loss: 2785.5686\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [14848/43919 (34%)]\tA-Loss: 2679.9321, V-Loss: 2009.0389\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [15360/43919 (35%)]\tA-Loss: 2769.0295, V-Loss: 2729.2815\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [15872/43919 (36%)]\tA-Loss: 2985.7593, V-Loss: 538.4272\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [16384/43919 (37%)]\tA-Loss: 2653.1001, V-Loss: 2294.0652\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [16896/43919 (38%)]\tA-Loss: 3191.7458, V-Loss: 5606.2920\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [17408/43919 (40%)]\tA-Loss: 2391.5342, V-Loss: 1175.0896\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [17920/43919 (41%)]\tA-Loss: 2656.3523, V-Loss: 3297.2695\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [18432/43919 (42%)]\tA-Loss: 2822.2061, V-Loss: 4030.5098\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [18944/43919 (43%)]\tA-Loss: 2698.4912, V-Loss: 4203.7827\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [19456/43919 (44%)]\tA-Loss: 3196.9915, V-Loss: 4876.0034\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [19968/43919 (45%)]\tA-Loss: 2625.5449, V-Loss: 4525.7573\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [20480/43919 (47%)]\tA-Loss: 3109.1211, V-Loss: 1198.3130\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [20992/43919 (48%)]\tA-Loss: 2916.2305, V-Loss: 1572.9524\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [21504/43919 (49%)]\tA-Loss: 2632.9473, V-Loss: 571.5874\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [22016/43919 (50%)]\tA-Loss: 2972.9275, V-Loss: 2053.1914\tAccuracy: 0.62500\n",
      "Train Epoch: 1 [22528/43919 (51%)]\tA-Loss: 2685.5068, V-Loss: 6832.7451\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [23040/43919 (52%)]\tA-Loss: 2980.6135, V-Loss: 495.1742\tAccuracy: 0.76562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23552/43919 (54%)]\tA-Loss: 3553.7783, V-Loss: 2594.9993\tAccuracy: 0.59375\n",
      "Train Epoch: 1 [24064/43919 (55%)]\tA-Loss: 2938.0081, V-Loss: 1304.6096\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [24576/43919 (56%)]\tA-Loss: 2904.7727, V-Loss: 1611.5281\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [25088/43919 (57%)]\tA-Loss: 2861.7549, V-Loss: 7547.5322\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [25600/43919 (58%)]\tA-Loss: 3062.0676, V-Loss: 398.2863\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [26112/43919 (59%)]\tA-Loss: 2546.7065, V-Loss: 616.1959\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [26624/43919 (61%)]\tA-Loss: 3140.0413, V-Loss: 712.2481\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [27136/43919 (62%)]\tA-Loss: 2753.9849, V-Loss: 1045.1151\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [27648/43919 (63%)]\tA-Loss: 2731.0645, V-Loss: 1371.9630\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [28160/43919 (64%)]\tA-Loss: 2613.8240, V-Loss: 3773.3608\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [28672/43919 (65%)]\tA-Loss: 3029.7029, V-Loss: 1498.4822\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [29184/43919 (66%)]\tA-Loss: 2859.8550, V-Loss: 1169.3931\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [29696/43919 (68%)]\tA-Loss: 2539.9309, V-Loss: 1068.7662\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [30208/43919 (69%)]\tA-Loss: 2784.7456, V-Loss: 543.9523\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [30720/43919 (70%)]\tA-Loss: 2659.7964, V-Loss: 1524.1974\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [31232/43919 (71%)]\tA-Loss: 2928.0535, V-Loss: 1550.1899\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [31744/43919 (72%)]\tA-Loss: 2737.6616, V-Loss: 1322.8687\tAccuracy: 0.67188\n",
      "Train Epoch: 1 [32256/43919 (73%)]\tA-Loss: 3136.4580, V-Loss: 562.2220\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [32768/43919 (75%)]\tA-Loss: 3143.3367, V-Loss: 5453.6709\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [33280/43919 (76%)]\tA-Loss: 3190.3625, V-Loss: 838.1284\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [33792/43919 (77%)]\tA-Loss: 3169.6055, V-Loss: 624.9461\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [34304/43919 (78%)]\tA-Loss: 2743.6206, V-Loss: 3235.9226\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [34816/43919 (79%)]\tA-Loss: 2769.4497, V-Loss: 1921.1171\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [35328/43919 (80%)]\tA-Loss: 2835.4124, V-Loss: 708.6329\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [35840/43919 (82%)]\tA-Loss: 2853.5452, V-Loss: 5849.9741\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [36352/43919 (83%)]\tA-Loss: 3191.9148, V-Loss: 5290.6963\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [36864/43919 (84%)]\tA-Loss: 2921.8984, V-Loss: 1048.2285\tAccuracy: 0.70312\n",
      "Train Epoch: 1 [37376/43919 (85%)]\tA-Loss: 2626.6726, V-Loss: 3662.9399\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [37888/43919 (86%)]\tA-Loss: 2718.4414, V-Loss: 4974.3335\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [38400/43919 (87%)]\tA-Loss: 2661.0027, V-Loss: 1485.3567\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [38912/43919 (89%)]\tA-Loss: 3208.2537, V-Loss: 856.2122\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [39424/43919 (90%)]\tA-Loss: 3016.2900, V-Loss: 2111.7322\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [39936/43919 (91%)]\tA-Loss: 2902.0881, V-Loss: 2260.6912\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [40448/43919 (92%)]\tA-Loss: 2815.7773, V-Loss: 1857.4659\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [40960/43919 (93%)]\tA-Loss: 3153.1143, V-Loss: 2241.3352\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [41472/43919 (94%)]\tA-Loss: 2832.7119, V-Loss: 845.6690\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [41984/43919 (96%)]\tA-Loss: 2676.6509, V-Loss: 2900.1951\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [42496/43919 (97%)]\tA-Loss: 2847.3787, V-Loss: 258.4159\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [43008/43919 (98%)]\tA-Loss: 2709.8462, V-Loss: 384.4585\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [43520/43919 (99%)]\tA-Loss: 2693.3750, V-Loss: 2927.1638\tAccuracy: 0.85938\n",
      "Average accepted score:  175.676\n",
      "Median score for accepted scores:  200.0\n",
      "Counter({200.0: 142, 127.0: 6, 149.0: 4, 184.0: 3, 130.0: 3, 182.0: 3, 134.0: 3, 114.0: 2, 158.0: 2, 117.0: 2, 174.0: 2, 148.0: 2, 89.0: 2, 171.0: 2, 137.0: 2, 152.0: 2, 175.0: 2, 91.0: 2, 170.0: 2, 138.0: 2, 159.0: 2, 193.0: 2, 185.0: 2, 179.0: 2, 183.0: 2, 168.0: 2, 160.0: 1, 176.0: 1, 181.0: 1, 109.0: 1, 129.0: 1, 162.0: 1, 118.0: 1, 116.0: 1, 101.0: 1, 188.0: 1, 105.0: 1, 187.0: 1, 125.0: 1, 96.0: 1, 128.0: 1, 104.0: 1, 177.0: 1, 169.0: 1, 135.0: 1, 167.0: 1, 155.0: 1, 198.0: 1, 92.0: 1, 195.0: 1, 161.0: 1, 124.0: 1, 103.0: 1, 142.0: 1, 107.0: 1, 77.0: 1, 112.0: 1, 136.0: 1, 66.0: 1, 192.0: 1, 191.0: 1, 131.0: 1, 111.0: 1, 147.0: 1, 141.0: 1, 156.0: 1, 83.0: 1, 115.0: 1, 123.0: 1, 79.0: 1, 76.0: 1, 132.0: 1, 197.0: 1, 94.0: 1})\n",
      "Current Policy:  76.34177215189874 74.0\n",
      "Policy Updated!\n",
      "New Policy:  175.676 200.0\n",
      "EPOCH ::: 1\n",
      "Train Epoch: 1 [512/45720 (1%)]\tA-Loss: 3427.9045, V-Loss: 8180.3667\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [1024/45720 (2%)]\tA-Loss: 3416.6697, V-Loss: 21938.5039\tAccuracy: 0.65625\n",
      "Train Epoch: 1 [1536/45720 (3%)]\tA-Loss: 3334.7224, V-Loss: 22536.2578\tAccuracy: 0.64062\n",
      "Train Epoch: 1 [2048/45720 (4%)]\tA-Loss: 3279.2395, V-Loss: 1743.5836\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [2560/45720 (6%)]\tA-Loss: 3131.4521, V-Loss: 13659.7490\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [3072/45720 (7%)]\tA-Loss: 2897.0684, V-Loss: 9575.7646\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [3584/45720 (8%)]\tA-Loss: 2364.9622, V-Loss: 20204.6348\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [4096/45720 (9%)]\tA-Loss: 2770.0171, V-Loss: 25887.0352\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [4608/45720 (10%)]\tA-Loss: 2528.8630, V-Loss: 4313.6577\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [5120/45720 (11%)]\tA-Loss: 4372.1436, V-Loss: 17148.4297\tAccuracy: 0.60938\n",
      "Train Epoch: 1 [5632/45720 (12%)]\tA-Loss: 2082.8750, V-Loss: 20947.3301\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [6144/45720 (13%)]\tA-Loss: 2327.4785, V-Loss: 9892.5566\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [6656/45720 (15%)]\tA-Loss: 2983.1785, V-Loss: 10013.3701\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [7168/45720 (16%)]\tA-Loss: 2677.4668, V-Loss: 12533.7070\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [7680/45720 (17%)]\tA-Loss: 2546.3291, V-Loss: 4982.9321\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [8192/45720 (18%)]\tA-Loss: 3157.6865, V-Loss: 10892.4062\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [8704/45720 (19%)]\tA-Loss: 2371.4163, V-Loss: 18927.0391\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [9216/45720 (20%)]\tA-Loss: 2128.2742, V-Loss: 654.1304\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [9728/45720 (21%)]\tA-Loss: 3708.2366, V-Loss: 774.6904\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [10240/45720 (22%)]\tA-Loss: 2546.6917, V-Loss: 902.3910\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [10752/45720 (24%)]\tA-Loss: 3329.0330, V-Loss: 1657.9464\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [11264/45720 (25%)]\tA-Loss: 3456.3545, V-Loss: 8619.8105\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [11776/45720 (26%)]\tA-Loss: 2914.0947, V-Loss: 833.5352\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [12288/45720 (27%)]\tA-Loss: 3436.9211, V-Loss: 1433.8375\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [12800/45720 (28%)]\tA-Loss: 3028.1450, V-Loss: 6575.3252\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [13312/45720 (29%)]\tA-Loss: 2068.8159, V-Loss: 1161.3033\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [13824/45720 (30%)]\tA-Loss: 3190.1423, V-Loss: 2595.7114\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [14336/45720 (31%)]\tA-Loss: 2365.7979, V-Loss: 881.0325\tAccuracy: 0.73438\n",
      "Train Epoch: 1 [14848/45720 (32%)]\tA-Loss: 3422.7039, V-Loss: 1817.7679\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [15360/45720 (34%)]\tA-Loss: 2377.8503, V-Loss: 3924.1787\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [15872/45720 (35%)]\tA-Loss: 2718.1753, V-Loss: 7185.9888\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [16384/45720 (36%)]\tA-Loss: 1887.1458, V-Loss: 676.3494\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [16896/45720 (37%)]\tA-Loss: 2564.7971, V-Loss: 2449.0413\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [17408/45720 (38%)]\tA-Loss: 2922.2881, V-Loss: 2217.8267\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [17920/45720 (39%)]\tA-Loss: 1859.3428, V-Loss: 784.3809\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [18432/45720 (40%)]\tA-Loss: 2302.5271, V-Loss: 4945.9771\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [18944/45720 (41%)]\tA-Loss: 1877.0372, V-Loss: 1245.1559\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [19456/45720 (43%)]\tA-Loss: 1828.3815, V-Loss: 916.5439\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [19968/45720 (44%)]\tA-Loss: 2155.1824, V-Loss: 1105.0851\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [20480/45720 (45%)]\tA-Loss: 2347.4656, V-Loss: 2305.0059\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [20992/45720 (46%)]\tA-Loss: 2243.3796, V-Loss: 1319.1151\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [21504/45720 (47%)]\tA-Loss: 2487.3469, V-Loss: 3611.1721\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [22016/45720 (48%)]\tA-Loss: 2500.1394, V-Loss: 4035.0217\tAccuracy: 0.68750\n",
      "Train Epoch: 1 [22528/45720 (49%)]\tA-Loss: 1987.1595, V-Loss: 375.8134\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [23040/45720 (50%)]\tA-Loss: 2094.1560, V-Loss: 3599.8401\tAccuracy: 0.85938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23552/45720 (52%)]\tA-Loss: 1632.0890, V-Loss: 2135.0947\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [24064/45720 (53%)]\tA-Loss: 1749.8239, V-Loss: 2100.2080\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [24576/45720 (54%)]\tA-Loss: 2423.8386, V-Loss: 2087.6260\tAccuracy: 0.71875\n",
      "Train Epoch: 1 [25088/45720 (55%)]\tA-Loss: 2084.0505, V-Loss: 2351.4299\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [25600/45720 (56%)]\tA-Loss: 2488.2314, V-Loss: 1753.1234\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [26112/45720 (57%)]\tA-Loss: 2947.8013, V-Loss: 7302.2500\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [26624/45720 (58%)]\tA-Loss: 2648.9839, V-Loss: 1084.2528\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [27136/45720 (59%)]\tA-Loss: 2378.5576, V-Loss: 4145.9775\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [27648/45720 (60%)]\tA-Loss: 2138.3816, V-Loss: 2124.9534\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [28160/45720 (62%)]\tA-Loss: 2375.1819, V-Loss: 1623.4657\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [28672/45720 (63%)]\tA-Loss: 2709.4246, V-Loss: 2412.3406\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [29184/45720 (64%)]\tA-Loss: 2567.4924, V-Loss: 4823.0581\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [29696/45720 (65%)]\tA-Loss: 1274.8119, V-Loss: 417.1421\tAccuracy: 0.95312\n",
      "Train Epoch: 1 [30208/45720 (66%)]\tA-Loss: 2614.8350, V-Loss: 1804.7671\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [30720/45720 (67%)]\tA-Loss: 2227.5295, V-Loss: 1118.7274\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [31232/45720 (68%)]\tA-Loss: 1801.4694, V-Loss: 4779.9468\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [31744/45720 (69%)]\tA-Loss: 2023.8657, V-Loss: 442.1281\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [32256/45720 (71%)]\tA-Loss: 1404.4630, V-Loss: 1650.5365\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [32768/45720 (72%)]\tA-Loss: 1844.9235, V-Loss: 4957.5859\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [33280/45720 (73%)]\tA-Loss: 1904.6859, V-Loss: 824.0674\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [33792/45720 (74%)]\tA-Loss: 1891.8234, V-Loss: 2837.8440\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [34304/45720 (75%)]\tA-Loss: 3014.0808, V-Loss: 8480.4922\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [34816/45720 (76%)]\tA-Loss: 2351.0615, V-Loss: 898.7895\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [35328/45720 (77%)]\tA-Loss: 3304.7178, V-Loss: 2960.1970\tAccuracy: 0.75000\n",
      "Train Epoch: 1 [35840/45720 (78%)]\tA-Loss: 1935.4391, V-Loss: 420.5517\tAccuracy: 0.93750\n",
      "Train Epoch: 1 [36352/45720 (80%)]\tA-Loss: 1934.8171, V-Loss: 577.5563\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [36864/45720 (81%)]\tA-Loss: 1838.0481, V-Loss: 1070.6969\tAccuracy: 0.84375\n",
      "Train Epoch: 1 [37376/45720 (82%)]\tA-Loss: 2272.0828, V-Loss: 2402.9216\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [37888/45720 (83%)]\tA-Loss: 1934.2411, V-Loss: 1997.9562\tAccuracy: 0.79688\n",
      "Train Epoch: 1 [38400/45720 (84%)]\tA-Loss: 1253.3041, V-Loss: 540.2072\tAccuracy: 0.92188\n",
      "Train Epoch: 1 [38912/45720 (85%)]\tA-Loss: 2656.4409, V-Loss: 1065.2775\tAccuracy: 0.76562\n",
      "Train Epoch: 1 [39424/45720 (86%)]\tA-Loss: 1967.4946, V-Loss: 4322.5659\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [39936/45720 (87%)]\tA-Loss: 1536.4418, V-Loss: 764.7305\tAccuracy: 0.90625\n",
      "Train Epoch: 1 [40448/45720 (88%)]\tA-Loss: 2249.1414, V-Loss: 3263.7434\tAccuracy: 0.78125\n",
      "Train Epoch: 1 [40960/45720 (90%)]\tA-Loss: 2484.4060, V-Loss: 2426.7881\tAccuracy: 0.82812\n",
      "Train Epoch: 1 [41472/45720 (91%)]\tA-Loss: 1707.8191, V-Loss: 2735.8826\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [41984/45720 (92%)]\tA-Loss: 1652.8652, V-Loss: 236.3007\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [42496/45720 (93%)]\tA-Loss: 1400.6077, V-Loss: 6405.9106\tAccuracy: 0.87500\n",
      "Train Epoch: 1 [43008/45720 (94%)]\tA-Loss: 2074.7510, V-Loss: 860.8859\tAccuracy: 0.81250\n",
      "Train Epoch: 1 [43520/45720 (95%)]\tA-Loss: 1407.5179, V-Loss: 822.1420\tAccuracy: 0.90625\n",
      "Train Epoch: 1 [44032/45720 (96%)]\tA-Loss: 1283.6779, V-Loss: 1391.9713\tAccuracy: 0.90625\n",
      "Train Epoch: 1 [44544/45720 (97%)]\tA-Loss: 1850.0811, V-Loss: 3360.9519\tAccuracy: 0.89062\n",
      "Train Epoch: 1 [45056/45720 (99%)]\tA-Loss: 1726.5267, V-Loss: 1913.8978\tAccuracy: 0.85938\n",
      "Train Epoch: 1 [45568/45720 (100%)]\tA-Loss: 1347.6948, V-Loss: 5784.1997\tAccuracy: 0.85938\n",
      "Average accepted score:  179.278\n",
      "Median score for accepted scores:  200.0\n",
      "Counter({200.0: 296, 127.0: 7, 184.0: 6, 192.0: 6, 130.0: 5, 182.0: 5, 140.0: 5, 149.0: 4, 176.0: 4, 152.0: 4, 185.0: 4, 168.0: 4, 117.0: 3, 174.0: 3, 148.0: 3, 125.0: 3, 128.0: 3, 137.0: 3, 159.0: 3, 169.0: 3, 134.0: 3, 179.0: 3, 183.0: 3, 155.0: 3, 131.0: 3, 197.0: 3, 126.0: 3, 163.0: 3, 173.0: 3, 114.0: 2, 158.0: 2, 181.0: 2, 109.0: 2, 129.0: 2, 188.0: 2, 187.0: 2, 89.0: 2, 171.0: 2, 104.0: 2, 175.0: 2, 91.0: 2, 170.0: 2, 177.0: 2, 138.0: 2, 193.0: 2, 195.0: 2, 124.0: 2, 142.0: 2, 112.0: 2, 136.0: 2, 191.0: 2, 147.0: 2, 141.0: 2, 156.0: 2, 123.0: 2, 132.0: 2, 164.0: 2, 157.0: 2, 122.0: 2, 153.0: 2, 178.0: 2, 143.0: 2, 160.0: 1, 162.0: 1, 118.0: 1, 116.0: 1, 101.0: 1, 105.0: 1, 96.0: 1, 135.0: 1, 167.0: 1, 198.0: 1, 92.0: 1, 161.0: 1, 103.0: 1, 107.0: 1, 77.0: 1, 66.0: 1, 111.0: 1, 83.0: 1, 115.0: 1, 79.0: 1, 76.0: 1, 94.0: 1, 121.0: 1, 119.0: 1, 154.0: 1, 120.0: 1, 139.0: 1, 166.0: 1, 172.0: 1, 151.0: 1, 144.0: 1, 133.0: 1, 199.0: 1})\n",
      "Current Policy:  175.676 200.0\n",
      "Policy Updated!\n",
      "New Policy:  179.278 200.0\n"
     ]
    }
   ],
   "source": [
    "test = Controller(Net())\n",
    "best_model = test.policyIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 197.6\n",
      "choice 1 (right): 0.4990  choice 0 (left): 0.5010\n",
      "Counter({200.0: 9, 176.0: 1})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.test(render = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suragnair's MCTS Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "\n",
    "    def __init__(self, nnet):\n",
    "        self.nnet = nnet    #fuction handle\n",
    "        self.c_puct = 0.1\n",
    "        self.Qsa = {}       # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores #times edge s,a was visited\n",
    "        self.Ns = {}        # stores #times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "    def search(self, s, reward, done):\n",
    "        # ---------------- TERMINAL STATE ---------------\n",
    "        if done == True:\n",
    "            return reward\n",
    "\n",
    "        # ------------- EXPLORING FROM A LEAF NODE ----------------------\n",
    "        #check if the state has a policy from it yet, if not then its a leaf\n",
    "        if s not in self.Ps:\n",
    "            self.Ps[s], v = self.nnet.predict(s)\n",
    "            \n",
    "            #check if the neural net has assigned a +ve prob to any policy\n",
    "             \n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s    # renormalize\n",
    "            else:\n",
    "                # if they were all zero then they are equally probable: (this shouldn't usually happen)\n",
    "                # NB! All valid moves may = 0 if NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                print(\"All valid moves were masked, do workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "        \n",
    "\n",
    "        # ------------- GET BEST ACTION -----------------------------\n",
    "        # search through the valid actions and update the UCB for all actions then update best acions\n",
    "        max_u, best_a = -float(\"inf\"), -1\n",
    "        for a in range(1):\n",
    "            if (s,a) in self.Qsa:\n",
    "                u = self.Qsa[(s,a)] + self.cpuct*self.Ps[s][a]*np.sqrt(self.Ns[s])/(1+self.Nsa[(s,a)])\n",
    "            else:\n",
    "                u = self.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s] + 1e-8)     # Q = 0 ?\n",
    "            \n",
    "            if u > max_u:\n",
    "                max_u = u\n",
    "                best_a = a\n",
    "        a = best_a\n",
    "\n",
    "        \n",
    "        # ----------- RECURSION TO NEXT STATE ------------------------\n",
    "        sp, reward, done, info = env.step(a)\n",
    "        v = self.search(sp, reward, done)\n",
    "        \n",
    "\n",
    "        # ------------ BACKUP Q-VALUES AND N_VISITED -----------------\n",
    "        # after we reach the terminal condition then the stack unwinds and we\n",
    "        # propagate up the tree backing up Q and N as we go\n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)]*self.Qsa[(s,a)] + v)/(self.Nsa[(s,a)]+1)\n",
    "            self.Nsa[(s,a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
